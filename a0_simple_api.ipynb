{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### OpenAI API",
   "id": "24aeb17d40f67591"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# SetUp library\n",
    "%pip install -U openai pydantic python-dotenv\n",
    "\n",
    "import os, sys, openai\n",
    "\n",
    "print(\"Python:\", sys.version)\n",
    "print(\"openai SDK:\", openai.__version__)\n",
    "print(\"Kernel:\", sys.executable)\n",
    "print(\"Has OPENAI_API_KEY?:\", \"OPENAI_API_KEY\" in os.environ)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Check API_KEY\n",
    "import os\n",
    "\n",
    "print(\"OPENAI_API_KEY:\", os.environ.get(\"OPENAI_API_KEY\", \"Not set\"))"
   ],
   "id": "36bd637100865fb9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### (1) responses.create：一般的な応答生成",
   "id": "646bfa0ec3c1b3ad"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "prompt = \"\"\"以下の要件で簡潔に回答してください：\n",
    "- 対象: Python学習者\n",
    "- トピック: OpenAI APIのはじめ方\n",
    "- 箇条書き3つ\n",
    "\"\"\"\n",
    "from openai import OpenAI\n",
    "\n",
    "# client = OpenAI()\n",
    "client = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "\n",
    "MODEL = \"gpt-5-mini\"\n",
    "\n",
    "resp = client.responses.create(\n",
    "    model=MODEL,\n",
    "    input=prompt,\n",
    ")\n",
    "\n",
    "print(resp.output_text)  # テキスト抽出の便利プロパティ"
   ],
   "id": "3113420afcad7f01",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "#### (2) responses.parse：構造化出力（Pydantic）",
   "id": "c47b616f9e946fef"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# responses.parse：構造化出力（Pydantic）\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from openai import OpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "import json, inspect, os\n",
    "\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))\n",
    "MODEL = os.getenv(\"OPENAI_MODEL\", \"gpt-5-mini\")  # 環境変数で上書き可\n",
    "\n",
    "class TodoItem(BaseModel):\n",
    "    title: str = Field(..., description=\"やることのタイトル\")\n",
    "    priority: int = Field(..., ge=1, le=5, description=\"1(低)〜5(高)\")\n",
    "    tags: List[str] = Field(default_factory=list)\n",
    "\n",
    "class TodoPlan(BaseModel):\n",
    "    owner: str\n",
    "    items: List[TodoItem]\n",
    "\n",
    "instruction = \"あなたは秘書です。日本語で、学習計画のToDoを構造化して返してください。\"\n",
    "user_text  = \"明日はOpenAIのResponses APIを勉強、週末はQdrantを触る。優先度高いのは明日の学習。タグは['api','vector']\"\n",
    "\n",
    "def to_json_schema(model_cls):\n",
    "    # pydantic v2 / v1 どちらでもOKにする\n",
    "    if hasattr(model_cls, \"model_json_schema\"):\n",
    "        return model_cls.model_json_schema()\n",
    "    return model_cls.schema()\n",
    "\n",
    "def parse_todo_plan():\n",
    "    # 1) 新SDK: responses.parse(text_format=MyModel)\n",
    "    try:\n",
    "        sig = inspect.signature(client.responses.parse)  # 存在確認\n",
    "        if \"text_format\" in sig.parameters:\n",
    "            resp = client.responses.parse(\n",
    "                model=MODEL,\n",
    "                instructions=instruction,\n",
    "                input=user_text,\n",
    "                text_format=TodoPlan,    # ← ココがポイント（schema ではない）\n",
    "            )\n",
    "            return getattr(resp, \"output_parsed\", getattr(resp, \"parsed\", resp))\n",
    "    except Exception as _:\n",
    "        pass\n",
    "\n",
    "    # 2) 構造化出力: responses.create(response_format=json_schema)\n",
    "    try:\n",
    "        schema = to_json_schema(TodoPlan)\n",
    "        resp = client.responses.create(\n",
    "            model=MODEL,\n",
    "            instructions=instruction,\n",
    "            input=user_text,\n",
    "            response_format={\n",
    "                \"type\": \"json_schema\",\n",
    "                \"json_schema\": {\"name\": \"TodoPlan\", \"schema\": schema, \"strict\": True},\n",
    "            },\n",
    "        )\n",
    "        data = json.loads(resp.output_text)\n",
    "        return TodoPlan.model_validate(data)\n",
    "    except TypeError:\n",
    "        # 古いSDKだと response_format 未対応 → 3) chat.completions(JSONモード)へ\n",
    "        pass\n",
    "\n",
    "    # 3) 互換: Chat Completions + JSONモード → Pydanticで検証\n",
    "    chat = client.chat.completions.create(\n",
    "        model=MODEL,  # 4o/5-mini等のJSONモード対応モデルを推奨\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"必ず有効なJSONのみを出力してください。\"},\n",
    "            {\"role\": \"user\", \"content\": f\"{instruction}\\nユーザー入力: {user_text}\\n出力は次のスキーマに厳密に従ってください: {to_json_schema(TodoPlan)}\"},\n",
    "        ],\n",
    "        response_format={\"type\": \"json_object\"},\n",
    "        temperature=0,\n",
    "    )\n",
    "    data = json.loads(chat.choices[0].message.content)\n",
    "    return TodoPlan.model_validate(data)\n",
    "\n",
    "parsed_plan = parse_todo_plan()\n",
    "print(parsed_plan)"
   ],
   "id": "c4ceac3c38607d1b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### (3) audio.speech.create：テキスト → 音声（TTS）",
   "id": "73a2cadfa5361c32"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# audio.speech.create\n",
    "from pathlib import Path\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "speech_path = Path(\"sample_ja.mp3\")\n",
    "\n",
    "# 推奨の軽量TTSモデル例（ドキュメントに基づく）\n",
    "with client.audio.speech.with_streaming_response.create(\n",
    "    model=\"gpt-4o-mini-tts\",\n",
    "    voice=\"alloy\",  # 他にverse, aria 等のバリエーションがある場合があります\n",
    "    input=\"こんにちは。今日はOpenAI APIの学習、何から始めますか？\",\n",
    ") as resp:\n",
    "    resp.stream_to_file(speech_path)\n",
    "\n",
    "display(Audio(filename=str(speech_path)))"
   ],
   "id": "775076638db71080",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### (4) audio.transcriptions.create：音声 → テキスト（日本語の文字起こし）",
   "id": "999422057e2fc3cb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "audio_file_path = \"sample_ja.mp3\"  # 例: 日本語音声ファイル\n",
    "\n",
    "with open(audio_file_path, \"rb\") as f:\n",
    "    transcript = client.audio.transcriptions.create(\n",
    "        model=\"gpt-4o-mini-transcribe\",  # 速く安価なSTTモデル\n",
    "        file=f,\n",
    "        response_format=\"text\",          # \"verbose_json\" なども可\n",
    "    )\n",
    "\n",
    "print(transcript.text if hasattr(transcript, \"text\") else transcript)"
   ],
   "id": "3c3d6ba8d289e135",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### (5) audio.translations.create：音声 → 英語テキスト（翻訳）",
   "id": "ac7feb09d78bba28"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# translation to English\nfrom openai import OpenAI\nclient = OpenAI()\n\naudio_file_path = \"sample_ja.mp3\"\n\nwith open(audio_file_path, \"rb\") as f:\n    # 音声を英語に翻訳するには translations.create() を使用\n    translation = client.audio.translations.create(\n        model=\"whisper-1\",  # translations では whisper-1 を使用\n        file=f,\n        response_format=\"text\",  # 文字列を直接返す\n    )\n\nprint(translation)  # response_format=\"text\" の場合は str",
   "id": "129b4ec833bc0628",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### (6) images.generate：画像生成（DALL·E系 / gpt-image-1）",
   "id": "e70f5d237c7573cc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "import base64\nfrom IPython.display import Image, display\n\nprompt = \"桜と富士山、夕焼け、浮世絵風のイラスト。高解像度で。\"\n\nimg = client.images.generate(\n    model=\"dall-e-3\",  # gpt-image-1 の代わりに dall-e-3 を使用\n    prompt=prompt,\n    size=\"1024x1024\",\n    n=1,\n    response_format=\"b64_json\",  # base64形式で取得\n)\n\nb64 = img.data[0].b64_json\nbinary = base64.b64decode(b64)\n\nout_path = \"fuji_sakura.png\"\nwith open(out_path, \"wb\") as f:\n    f.write(binary)\n\ndisplay(Image(filename=out_path))",
   "id": "6f347e2daf1c46",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### (7) chat.completions.create：チャット完了API",
   "id": "2b621f5b204a9b63"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "chat = client.chat.completions.create(\n    model=MODEL,\n    messages=[\n        {\"role\": \"system\", \"content\": \"あなたは有能なPythonメンターです。\"},\n        {\"role\": \"user\", \"content\": \"OpenAI APIでJSONの構造化出力を行うには？\"},\n    ],\n    # temperature=0.2,  # gpt-5-miniはデフォルト値(1)のみサポート\n)\n\nprint(chat.choices[0].message.content)",
   "id": "3bf94d92f1bcde7c",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
