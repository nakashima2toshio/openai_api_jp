# streamlit run a06_reasoning_chain_of_thought.py --server.port=8506
# --------------------------------------------------
# OpenAI Chain of Thought æ¨è«–ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ‡ãƒ¢ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆçµ±ä¸€åŒ–ç‰ˆï¼‰
# Streamlitã‚’ä½¿ç”¨ã—ãŸã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªAPIãƒ†ã‚¹ãƒˆãƒ„ãƒ¼ãƒ«
# çµ±ä¸€åŒ–ç‰ˆ: a10_00_responses_api.pyã®æ§‹æˆãƒ»æ§‹é€ ãƒ»ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãƒ»ã‚¨ãƒ©ãƒ¼å‡¦ç†ã®å®Œå…¨çµ±ä¸€
# --------------------------------------------------
import os
import sys
import json
import logging
from datetime import datetime
import time
from abc import ABC, abstractmethod
from typing import Optional, List, Dict, Any, Union
from pathlib import Path

import streamlit as st
import pandas as pd
from pydantic import BaseModel, Field, ValidationError

from openai import OpenAI
from openai.types.responses import (
    EasyInputMessageParam,
    ResponseInputTextParam,
    ResponseInputImageParam,
    ResponseFormatTextJSONSchemaConfigParam,
    ResponseTextConfigParam,
    FileSearchToolParam,
    WebSearchToolParam,
    ComputerToolParam,
    Response,
)

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®è¨­å®š
BASE_DIR = Path(__file__).resolve().parent.parent
THIS_DIR = Path(__file__).resolve().parent

# PYTHONPATHã«è¦ªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’è¿½åŠ 
sys.path.insert(0, str(BASE_DIR))

# ãƒ˜ãƒ«ãƒ‘ãƒ¼ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆçµ±ä¸€åŒ–ï¼‰
try:
    from helper_st import (
        UIHelper, MessageManagerUI, ResponseProcessorUI,
        SessionStateManager, error_handler_ui, timer_ui,
        InfoPanelManager, safe_streamlit_json
    )
    from helper_api import (
        config, logger, TokenManager, OpenAIClient,
        EasyInputMessageParam, ResponseInputTextParam,
        ConfigManager, MessageManager, sanitize_key,
        error_handler, timer, get_default_messages,
        ResponseProcessor, format_timestamp
    )
except ImportError as e:
    st.error(f"ãƒ˜ãƒ«ãƒ‘ãƒ¼ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
    st.info("å¿…è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„: helper_st.py, helper_api.py")
    st.stop()


# ãƒšãƒ¼ã‚¸è¨­å®š
def setup_page_config():
    """ãƒšãƒ¼ã‚¸è¨­å®šï¼ˆé‡è¤‡å®Ÿè¡Œã‚¨ãƒ©ãƒ¼å›é¿ï¼‰"""
    try:
        st.set_page_config(
            page_title=config.get("ui.page_title", "OpenAI Chain of Thought æ¨è«–ãƒ‘ã‚¿ãƒ¼ãƒ³ãƒ‡ãƒ¢"),
            page_icon=config.get("ui.page_icon", "ğŸ§ "),
            layout=config.get("ui.layout", "wide"),
            initial_sidebar_state="expanded"
        )
    except st.errors.StreamlitAPIException:
        # æ—¢ã«è¨­å®šæ¸ˆã¿ã®å ´åˆã¯ç„¡è¦–
        pass


# ãƒšãƒ¼ã‚¸è¨­å®šã®å®Ÿè¡Œ
setup_page_config()


# ==================================================
# å…±é€šUIé–¢æ•°ï¼ˆçµ±ä¸€åŒ–ç‰ˆï¼‰
# ==================================================
def setup_common_ui(demo_name: str, selected_model: str):
    """å…±é€šUIè¨­å®šï¼ˆçµ±ä¸€åŒ–ç‰ˆï¼‰"""
    # ãƒ˜ãƒƒãƒ€ãƒ¼è¡¨ç¤º
    st.write(f"# {demo_name}")
    st.write("é¸æŠã—ãŸãƒ¢ãƒ‡ãƒ«:", selected_model)


def setup_sidebar_panels(selected_model: str):
    """ã‚µã‚¤ãƒ‰ãƒãƒ¼ãƒ‘ãƒãƒ«ã®çµ±ä¸€è¨­å®šï¼ˆhelper_st.pyã®InfoPanelManagerã‚’ä½¿ç”¨ï¼‰"""
    st.sidebar.write("### ğŸ“‹ æƒ…å ±ãƒ‘ãƒãƒ«")
    
    # InfoPanelManagerã‚’ä½¿ç”¨ã—ãŸçµ±ä¸€ãƒ‘ãƒãƒ«è¨­å®š
    InfoPanelManager.show_model_info(selected_model)
    InfoPanelManager.show_session_info()
    InfoPanelManager.show_cost_info(selected_model)
    InfoPanelManager.show_performance_info()
    InfoPanelManager.show_debug_panel()
    InfoPanelManager.show_settings()


# ==================================================
# CoTãƒ‘ã‚¿ãƒ¼ãƒ³çµæœãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«ï¼ˆçµ±ä¸€åŒ–ç‰ˆï¼‰
# ==================================================
class StepByStepResult(BaseModel):
    """Step-by-Stepãƒ‘ã‚¿ãƒ¼ãƒ³ã®çµæœ"""
    question: str = Field(..., description="è³ªå•")
    steps: List[str] = Field(..., description="è§£æ±ºã‚¹ãƒ†ãƒƒãƒ—")
    answer: str = Field(..., description="æœ€çµ‚çš„ãªç­”ãˆ")
    confidence: Optional[float] = Field(None, description="ä¿¡é ¼åº¦")


class HypothesisTestResult(BaseModel):
    """Hypothesis-Testãƒ‘ã‚¿ãƒ¼ãƒ³ã®çµæœ"""
    problem: str = Field(..., description="å•é¡Œ")
    hypothesis: str = Field(..., description="ä»®èª¬")
    evidence: List[str] = Field(default_factory=list, description="è¨¼æ‹ ãƒ»å®Ÿé¨“")
    evaluation: str = Field(..., description="è©•ä¾¡")
    conclusion: str = Field(..., description="çµè«–")
    confidence_score: Optional[float] = Field(None, description="ä¿¡é ¼åº¦ã‚¹ã‚³ã‚¢")


class TreeOfThoughtResult(BaseModel):
    """Tree-of-Thoughtãƒ‘ã‚¿ãƒ¼ãƒ³ã®çµæœ"""
    goal: str = Field(..., description="ç›®æ¨™")
    exploration_paths: List[str] = Field(default_factory=list, description="æ¢ç´¢ãƒ‘ã‚¹")
    best_solution: str = Field(..., description="æœ€é©è§£")
    evaluation_score: Optional[float] = Field(None, description="è©•ä¾¡ã‚¹ã‚³ã‚¢")


class ProsConsDecisionResult(BaseModel):
    """Pros-Cons-Decisionãƒ‘ã‚¿ãƒ¼ãƒ³ã®çµæœ"""
    topic: str = Field(..., description="ãƒˆãƒ”ãƒƒã‚¯")
    pros: List[str] = Field(default_factory=list, description="ãƒ¡ãƒªãƒƒãƒˆ")
    cons: List[str] = Field(default_factory=list, description="ãƒ‡ãƒ¡ãƒªãƒƒãƒˆ")
    decision: str = Field(..., description="æ±ºå®š")
    rationale: str = Field(..., description="æ ¹æ‹ ")
    confidence: Optional[float] = Field(None, description="æ±ºå®šã¸ã®ä¿¡é ¼åº¦")


class PlanExecuteReflectResult(BaseModel):
    """Plan-Execute-Reflectãƒ‘ã‚¿ãƒ¼ãƒ³ã®çµæœ"""
    objective: str = Field(..., description="ç›®æ¨™")
    initial_plan: List[str] = Field(default_factory=list, description="åˆæœŸè¨ˆç”»")
    execution_results: List[str] = Field(default_factory=list, description="å®Ÿè¡Œçµæœ")
    reflections: List[str] = Field(default_factory=list, description="æŒ¯ã‚Šè¿”ã‚Š")
    improved_plan: List[str] = Field(default_factory=list, description="æ”¹å–„ã•ã‚ŒãŸè¨ˆç”»")
    lessons_learned: List[str] = Field(default_factory=list, description="å­¦ã‚“ã æ•™è¨“")
    success_probability: Optional[float] = Field(None, description="æˆåŠŸç¢ºç‡")


# ==================================================
# ãƒ™ãƒ¼ã‚¹ãƒ‡ãƒ¢ã‚¯ãƒ©ã‚¹ï¼ˆçµ±ä¸€åŒ–ç‰ˆï¼‰
# ==================================================
class BaseDemo(ABC):
    """ãƒ™ãƒ¼ã‚¹ãƒ‡ãƒ¢ã‚¯ãƒ©ã‚¹ï¼ˆçµ±ä¸€åŒ–ç‰ˆï¼‰"""
    
    def __init__(self, demo_name: str):
        self.demo_name = demo_name
        self.safe_key = sanitize_key(demo_name)
        self.model = None
        self.client = None
    
    @abstractmethod
    def run_demo(self):
        """ãƒ‡ãƒ¢ã®å®Ÿè¡Œï¼ˆã‚µãƒ–ã‚¯ãƒ©ã‚¹ã§å®Ÿè£…ï¼‰"""
        pass
    
    @error_handler_ui
    @timer_ui
    def execute(self, selected_model: str):
        """ãƒ‡ãƒ¢ã®å®Ÿè¡Œï¼ˆçµ±ä¸€ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ï¼‰"""
        # é¸æŠã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’è¨­å®š
        self.model = selected_model
        
        # å…±é€šUIè¨­å®š
        setup_common_ui(self.demo_name, selected_model)
        
        # OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–
        try:
            self.client = OpenAI()
        except Exception as e:
            st.error(f"OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            return
        
        # ãƒ‡ãƒ¢å®Ÿè¡Œ
        self.run_demo()


# ==================================================
# Chain of Thought ãƒ‡ãƒ¢ã‚¯ãƒ©ã‚¹ï¼ˆçµ±ä¸€åŒ–ç‰ˆï¼‰
# ==================================================
class StepByStepReasoningDemo(BaseDemo):
    """æ®µéšçš„æ¨è«–ï¼ˆStep-by-Stepï¼‰ãƒ‡ãƒ¢"""

    def run_demo(self):
        """æ®µéšçš„æ¨è«–ãƒ‡ãƒ¢ã®å®Ÿè¡Œ"""
        st.write("## å®Ÿè£…ä¾‹: Step-by-Step æ¨è«–")
        st.write("å•é¡Œã‚’æ®µéšçš„ã«åˆ†è§£ã—ã€é †åºç«‹ã¦ã¦è§£æ±ºã™ã‚‹æ¨è«–ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å®Ÿè£…ã—ã¾ã™ã€‚")
        
        # å®Ÿè£…ä¾‹ã‚µãƒ³ãƒ—ãƒ«è¡¨ç¤º
        with st.expander("ğŸ“‹ å®Ÿè£…ä¾‹ã‚³ãƒ¼ãƒ‰", expanded=False):
            st.code("""
# Step-by-Step æ¨è«–ã®å®Ÿè£…ä¾‹
from openai import OpenAI
from openai.types.responses import EasyInputMessageParam, ResponseInputTextParam

client = OpenAI()

system_prompt = '''ã‚ãªãŸã¯æ®µéšçš„ã«å•é¡Œã‚’è§£ã methodical ãªãƒãƒ¥ãƒ¼ã‚¿ãƒ¼ã§ã™ã€‚
è³ªå•ãŒä¸ãˆã‚‰ã‚ŒãŸã‚‰ï¼š
1. å•é¡Œã‚’æ˜ç¢ºã§é †åºç«‹ã£ãŸã‚¹ãƒ†ãƒƒãƒ—ã«åˆ†è§£ã—ã¦ãã ã•ã„
2. å„ã‚¹ãƒ†ãƒƒãƒ—ã«ç•ªå·ã‚’ä»˜ã‘ã¦ãã ã•ã„ï¼ˆStep 1:, Step 2: ãªã©ï¼‰
3. ä½œæ¥­ã‚’æ˜ç¢ºã«ç¤ºã—ã¦ãã ã•ã„
4. æœ€å¾Œã« "Answer:" ã«ç¶šã‘ã¦æœ€çµ‚çš„ãªç­”ãˆã‚’è¨˜è¼‰ã—ã¦ãã ã•ã„
5. è§£ç­”ã®ä¿¡é ¼åº¦ã‚’0-1ã§è©•ä¾¡ã—ã¦ãã ã•ã„

æ¨è«–ã«ãŠã„ã¦æ­£ç¢ºã§è«–ç†çš„ã«ã—ã¦ãã ã•ã„ã€‚'''

messages = [
    EasyInputMessageParam(role="system", content=system_prompt),
    EasyInputMessageParam(
        role="user",
        content=[
            ResponseInputTextParam(
                type="input_text", 
                text="2X + 1 = 5ã®ã¨ãã€Xã¯ã„ãã¤ï¼Ÿ"
            )
        ]
    )
]

response = client.responses.create(model=model, input=messages)
            """, language="python")
        
        # å…¥åŠ›ã‚¨ãƒªã‚¢
        st.subheader("ğŸ“¤ å…¥åŠ›")
        
        question = st.text_area(
            "è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„",
            value="2X + 1 = 5ã®ã¨ãã€Xã¯ã„ãã¤ï¼Ÿ",
            height=config.get("ui.text_area_height", 75),
            key=f"question_{self.safe_key}"
        )
        
        if st.button("ğŸš€ æ®µéšçš„æ¨è«–ã‚’å®Ÿè¡Œ", key=f"submit_{self.safe_key}"):
            if question:
                self._process_step_by_step_reasoning(question)
        
        # çµæœè¡¨ç¤º
        self._display_reasoning_results()
    
    def _process_step_by_step_reasoning(self, question: str):
        """æ®µéšçš„æ¨è«–ã®å‡¦ç†"""
        try:
            system_prompt = """ã‚ãªãŸã¯æ®µéšçš„ã«å•é¡Œã‚’è§£ã methodical ãªãƒãƒ¥ãƒ¼ã‚¿ãƒ¼ã§ã™ã€‚
è³ªå•ãŒä¸ãˆã‚‰ã‚ŒãŸã‚‰ï¼š
1. å•é¡Œã‚’æ˜ç¢ºã§é †åºç«‹ã£ãŸã‚¹ãƒ†ãƒƒãƒ—ã«åˆ†è§£ã—ã¦ãã ã•ã„
2. å„ã‚¹ãƒ†ãƒƒãƒ—ã«ç•ªå·ã‚’ä»˜ã‘ã¦ãã ã•ã„ï¼ˆStep 1:, Step 2: ãªã©ï¼‰
3. ä½œæ¥­ã‚’æ˜ç¢ºã«ç¤ºã—ã¦ãã ã•ã„
4. æœ€å¾Œã« "Answer:" ã«ç¶šã‘ã¦æœ€çµ‚çš„ãªç­”ãˆã‚’è¨˜è¼‰ã—ã¦ãã ã•ã„
5. è§£ç­”ã®ä¿¡é ¼åº¦ã‚’0-1ã§è©•ä¾¡ã—ã¦ãã ã•ã„

æ¨è«–ã«ãŠã„ã¦æ­£ç¢ºã§è«–ç†çš„ã«ã—ã¦ãã ã•ã„ã€‚"""
            
            messages = [
                EasyInputMessageParam(role="system", content=system_prompt),
                EasyInputMessageParam(
                    role="user",
                    content=[
                        ResponseInputTextParam(
                            type="input_text",
                            text=question
                        )
                    ]
                )
            ]
            
            with st.spinner("æ®µéšçš„æ¨è«–ä¸­..."):
                response = self.client.responses.create(
                    model=self.model,
                    input=messages
                )
            
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜
            st.session_state[f"reasoning_response_{self.safe_key}"] = response
            st.success("âœ… æ®µéšçš„æ¨è«–å®Œäº†")
            st.rerun()
            
        except Exception as e:
            st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            if config.get("experimental.debug_mode", False):
                st.exception(e)
    
    def _display_reasoning_results(self):
        """æ¨è«–çµæœã®è¡¨ç¤º"""
        if f"reasoning_response_{self.safe_key}" in st.session_state:
            response = st.session_state[f"reasoning_response_{self.safe_key}"]
            st.subheader("ğŸ¤– æ®µéšçš„æ¨è«–çµæœ")
            ResponseProcessorUI.display_response(response)


class HypothesisTestDemo(BaseDemo):
    """ä»®èª¬æ¤œè¨¼æ¨è«–ãƒ‡ãƒ¢"""

    def run_demo(self):
        """ä»®èª¬æ¤œè¨¼æ¨è«–ãƒ‡ãƒ¢ã®å®Ÿè¡Œ"""
        st.write("## å®Ÿè£…ä¾‹: ä»®èª¬æ¤œè¨¼æ¨è«–")
        st.write("ä»®èª¬ã‚’ç«‹ã¦ã¦è¨¼æ‹ ã§æ¤œè¨¼ã™ã‚‹æ¨è«–ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å®Ÿè£…ã—ã¾ã™ã€‚")
        
        # å®Ÿè£…ä¾‹ã‚µãƒ³ãƒ—ãƒ«è¡¨ç¤º
        with st.expander("ğŸ“‹ å®Ÿè£…ä¾‹ã‚³ãƒ¼ãƒ‰", expanded=False):
            st.code("""
# ä»®èª¬æ¤œè¨¼æ¨è«–ã®å®Ÿè£…ä¾‹
from openai import OpenAI
from openai.types.responses import EasyInputMessageParam, ResponseInputTextParam

client = OpenAI()

system_prompt = '''ã‚ãªãŸã¯ä»®èª¬æ¤œè¨¼æ–¹æ³•è«–ã«å¾“ã†ä¸Šç´šã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã§ã™ã€‚
å•é¡Œã¨ä»®èª¬ãŒä¸ãˆã‚‰ã‚ŒãŸã‚‰ï¼š
1. è¨¼æ‹ ã¨ã—ã¦å°‘ãªãã¨ã‚‚3ã¤ã®å…·ä½“çš„ãªãƒ†ã‚¹ãƒˆã¾ãŸã¯æ¸¬å®šã‚’ç”Ÿæˆ
2. è¨¼æ‹ ãŒä»®èª¬ã‚’æ”¯æŒã™ã‚‹ã‹åè¨¼ã™ã‚‹ã‹ã‚’è©•ä¾¡
3. ä»®èª¬ã‚’å—ã‘å…¥ã‚Œã‚‹ã‹æ‹’å¦ã™ã‚‹ã‹ã®æ˜ç¢ºãªçµè«–ã‚’æä¾›
4. çµè«–ã¸ã®ä¿¡é ¼åº¦ã‚’è©•ä¾¡ï¼ˆ0-1ï¼‰

ä»¥ä¸‹ã®æ˜ç¢ºãªã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§æ§‹é€ åŒ–ã•ã‚ŒãŸå‡ºåŠ›ã‚’è¿”ã—ã¦ãã ã•ã„ï¼š
- Evidenceï¼ˆãƒ†ã‚¹ãƒˆ/æ¸¬å®šã®ç•ªå·ä»˜ããƒªã‚¹ãƒˆï¼‰
- Evaluationï¼ˆè¨¼æ‹ ã®åˆ†æï¼‰
- Conclusionï¼ˆç†ç”±ä»˜ãã§å—è«¾/æ‹’å¦ï¼‰
- Confidence Scoreï¼ˆ0-1ï¼‰'''

messages = [
    EasyInputMessageParam(role="system", content=system_prompt),
    EasyInputMessageParam(
        role="user",
        content=[
            ResponseInputTextParam(
                type="input_text", 
                text="Problem: Webã‚¢ãƒ—ãƒªã®åˆå›è¡¨ç¤ºãŒ3ç§’ä»¥ä¸Šã‹ã‹ã‚‹\\nHypothesis: ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚µã‚¤ã‚ºãŒå¤§ãã™ãã¦èª­ã¿è¾¼ã¿æ™‚é–“ã‚’åœ§è¿«ã—ã¦ã„ã‚‹"
            )
        ]
    )
]

response = client.responses.create(model=model, input=messages)
            """, language="python")
        
        # å…¥åŠ›ã‚¨ãƒªã‚¢
        st.subheader("ğŸ“¤ å…¥åŠ›")
        
        problem = st.text_area(
            "å•é¡Œï¼ˆãƒã‚°ãƒ»å®Ÿé¨“ç›®çš„ï¼‰",
            value="Webã‚¢ãƒ—ãƒªã®åˆå›è¡¨ç¤ºãŒ3ç§’ä»¥ä¸Šã‹ã‹ã‚‹",
            height=config.get("ui.text_area_height", 75),
            key=f"problem_{self.safe_key}"
        )
        
        hypothesis = st.text_input(
            "ä»®èª¬ï¼ˆåŸå› ãƒ»æ”¹å–„æ¡ˆï¼‰",
            value="ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚µã‚¤ã‚ºãŒå¤§ãã™ãã¦èª­ã¿è¾¼ã¿æ™‚é–“ã‚’åœ§è¿«ã—ã¦ã„ã‚‹",
            key=f"hypothesis_{self.safe_key}"
        )
        
        if st.button("ğŸ§ª ä»®èª¬æ¤œè¨¼ã‚’å®Ÿè¡Œ", key=f"submit_{self.safe_key}"):
            if problem and hypothesis:
                self._process_hypothesis_test(problem, hypothesis)
        
        # çµæœè¡¨ç¤º
        self._display_hypothesis_results()
    
    def _process_hypothesis_test(self, problem: str, hypothesis: str):
        """ä»®èª¬æ¤œè¨¼ã®å‡¦ç†"""
        try:
            system_prompt = """ã‚ãªãŸã¯ä»®èª¬æ¤œè¨¼æ–¹æ³•è«–ã«å¾“ã†ä¸Šç´šã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ã§ã™ã€‚
å•é¡Œã¨ä»®èª¬ãŒä¸ãˆã‚‰ã‚ŒãŸã‚‰ï¼š
1. è¨¼æ‹ ã¨ã—ã¦å°‘ãªãã¨ã‚‚3ã¤ã®å…·ä½“çš„ãªãƒ†ã‚¹ãƒˆã¾ãŸã¯æ¸¬å®šã‚’ç”Ÿæˆ
2. è¨¼æ‹ ãŒä»®èª¬ã‚’æ”¯æŒã™ã‚‹ã‹åè¨¼ã™ã‚‹ã‹ã‚’è©•ä¾¡
3. ä»®èª¬ã‚’å—ã‘å…¥ã‚Œã‚‹ã‹æ‹’å¦ã™ã‚‹ã‹ã®æ˜ç¢ºãªçµè«–ã‚’æä¾›
4. çµè«–ã¸ã®ä¿¡é ¼åº¦ã‚’è©•ä¾¡ï¼ˆ0-1ï¼‰

ä»¥ä¸‹ã®æ˜ç¢ºãªã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§æ§‹é€ åŒ–ã•ã‚ŒãŸå‡ºåŠ›ã‚’è¿”ã—ã¦ãã ã•ã„ï¼š
- Evidenceï¼ˆãƒ†ã‚¹ãƒˆ/æ¸¬å®šã®ç•ªå·ä»˜ããƒªã‚¹ãƒˆï¼‰
- Evaluationï¼ˆè¨¼æ‹ ã®åˆ†æï¼‰
- Conclusionï¼ˆç†ç”±ä»˜ãã§å—è«¾/æ‹’å¦ï¼‰
- Confidence Scoreï¼ˆ0-1ï¼‰

ã‚¢ãƒ—ãƒ­ãƒ¼ãƒã«ãŠã„ã¦ä½“ç³»çš„ã§ç§‘å­¦çš„ã«ã—ã¦ãã ã•ã„ã€‚"""
            
            user_content = f"Problem: {problem}\nHypothesis: {hypothesis}"
            
            messages = [
                EasyInputMessageParam(role="system", content=system_prompt),
                EasyInputMessageParam(
                    role="user",
                    content=[
                        ResponseInputTextParam(
                            type="input_text",
                            text=user_content
                        )
                    ]
                )
            ]
            
            with st.spinner("ä»®èª¬æ¤œè¨¼ä¸­..."):
                response = self.client.responses.create(
                    model=self.model,
                    input=messages
                )
            
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜
            st.session_state[f"hypothesis_response_{self.safe_key}"] = response
            st.success("âœ… ä»®èª¬æ¤œè¨¼å®Œäº†")
            st.rerun()
            
        except Exception as e:
            st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            if config.get("experimental.debug_mode", False):
                st.exception(e)
    
    def _display_hypothesis_results(self):
        """ä»®èª¬æ¤œè¨¼çµæœã®è¡¨ç¤º"""
        if f"hypothesis_response_{self.safe_key}" in st.session_state:
            response = st.session_state[f"hypothesis_response_{self.safe_key}"]
            st.subheader("ğŸ¤– ä»®èª¬æ¤œè¨¼çµæœ")
            ResponseProcessorUI.display_response(response)


class TreeOfThoughtDemo(BaseDemo):
    """æ€è€ƒã®æœ¨ï¼ˆTree of Thoughtï¼‰ãƒ‡ãƒ¢"""

    def run_demo(self):
        """æ€è€ƒã®æœ¨ãƒ‡ãƒ¢ã®å®Ÿè¡Œ"""
        st.write("## å®Ÿè£…ä¾‹: Tree of Thought æ¨è«–")
        st.write("è¤‡æ•°ã®æ€è€ƒçµŒè·¯ã‚’æ¢ç´¢ã—ã¦æœ€é©è§£ã‚’ç™ºè¦‹ã™ã‚‹æ¨è«–ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å®Ÿè£…ã—ã¾ã™ã€‚")
        
        # å®Ÿè£…ä¾‹ã‚µãƒ³ãƒ—ãƒ«è¡¨ç¤º
        with st.expander("ğŸ“‹ å®Ÿè£…ä¾‹ã‚³ãƒ¼ãƒ‰", expanded=False):
            st.code("""
# Tree of Thought æ¨è«–ã®å®Ÿè£…ä¾‹
from openai import OpenAI
from openai.types.responses import EasyInputMessageParam, ResponseInputTextParam

client = OpenAI()

system_prompt = '''ã‚ãªãŸã¯Tree-of-Thoughtsæ¢ç´¢ã‚’å®Ÿè¡Œã™ã‚‹AIã§ã™ã€‚
ä½“ç³»çš„ãªåˆ†å²æ¨è«–ã§å•é¡Œã‚’è§£æ±ºã—ã¾ã™ã€‚

å„å•é¡Œã«å¯¾ã—ã¦ï¼š
1. å„ã‚¹ãƒ†ãƒƒãƒ—ã§è¤‡æ•°ã®å€™è£œæ€è€ƒã‚’ç”Ÿæˆï¼ˆåˆ†å²ï¼‰
2. å„åˆ†å²ã‚’0-1ã®ã‚¹ã‚³ã‚¢ã§è©•ä¾¡
3. æœ‰æœ›ãªåˆ†å²ã‚’ã•ã‚‰ãªã‚‹æ¢ç´¢ã®ãŸã‚ã«é¸æŠ
4. æ¢ç´¢ãƒ„ãƒªãƒ¼æ§‹é€ ã‚’è¿½è·¡
5. è§£æ±ºã¸ã®æœ€é©ãƒ‘ã‚¹ã‚’ç‰¹å®š

ä»¥ä¸‹ã‚’å«ã‚€æ§‹é€ åŒ–ã•ã‚ŒãŸå‡ºåŠ›ã‚’è¿”ã—ã¦ãã ã•ã„ï¼š
- è¤‡æ•°ã®åˆ†å²ã¨ãã®è©•ä¾¡ã‚¹ã‚³ã‚¢
- åˆ†å²é–“ã®é–¢ä¿‚æ€§
- æœ€é©ãƒ‘ã‚¹ã®ç‰¹å®š
- æœ€çµ‚çš„ãªè§£æ±ºç­–

å˜ãªã‚‹ç·šå½¢æ€è€ƒã§ã¯ãªãã€ä½“ç³»çš„ãªæ¢ç´¢ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚'''

messages = [
    EasyInputMessageParam(role="system", content=system_prompt),
    EasyInputMessageParam(
        role="user",
        content=[
            ResponseInputTextParam(
                type="input_text", 
                text="Goal: 4, 9, 10, 13 ã®æ•°å­—ã‚’ä½¿ã£ã¦24ã‚’ä½œã‚‹ï¼ˆå››å‰‡æ¼”ç®—ã®ã¿ä½¿ç”¨ï¼‰"
            )
        ]
    )
]

response = client.responses.create(model=model, input=messages)
            """, language="python")
        
        # å…¥åŠ›ã‚¨ãƒªã‚¢
        st.subheader("ğŸ“¤ å…¥åŠ›")
        
        goal = st.text_area(
            "ç›®æ¨™ï¼ˆé”æˆã—ãŸã„ã‚¿ã‚¹ã‚¯ï¼‰",
            value="4, 9, 10, 13 ã®æ•°å­—ã‚’ä½¿ã£ã¦24ã‚’ä½œã‚‹ï¼ˆå››å‰‡æ¼”ç®—ã®ã¿ä½¿ç”¨ï¼‰",
            height=config.get("ui.text_area_height", 75),
            key=f"goal_{self.safe_key}"
        )
        
        if st.button("ğŸŒ³ Tree of Thought ã‚’å®Ÿè¡Œ", key=f"submit_{self.safe_key}"):
            if goal:
                self._process_tree_of_thought(goal)
        
        # çµæœè¡¨ç¤º
        self._display_tree_results()
    
    def _process_tree_of_thought(self, goal: str):
        """Tree of Thought ã®å‡¦ç†"""
        try:
            system_prompt = """ã‚ãªãŸã¯Tree-of-Thoughtsæ¢ç´¢ã‚’å®Ÿè¡Œã™ã‚‹AIã§ã™ã€‚
ä½“ç³»çš„ãªåˆ†å²æ¨è«–ã§å•é¡Œã‚’è§£æ±ºã—ã¾ã™ã€‚

å„å•é¡Œã«å¯¾ã—ã¦ï¼š
1. å„ã‚¹ãƒ†ãƒƒãƒ—ã§è¤‡æ•°ã®å€™è£œæ€è€ƒã‚’ç”Ÿæˆï¼ˆåˆ†å²ï¼‰
2. å„åˆ†å²ã‚’0-1ã®ã‚¹ã‚³ã‚¢ã§è©•ä¾¡
3. æœ‰æœ›ãªåˆ†å²ã‚’ã•ã‚‰ãªã‚‹æ¢ç´¢ã®ãŸã‚ã«é¸æŠ
4. æ¢ç´¢ãƒ„ãƒªãƒ¼æ§‹é€ ã‚’è¿½è·¡
5. è§£æ±ºã¸ã®æœ€é©ãƒ‘ã‚¹ã‚’ç‰¹å®š

ä»¥ä¸‹ã‚’å«ã‚€æ§‹é€ åŒ–ã•ã‚ŒãŸå‡ºåŠ›ã‚’è¿”ã—ã¦ãã ã•ã„ï¼š
- è¤‡æ•°ã®åˆ†å²ã¨ãã®è©•ä¾¡ã‚¹ã‚³ã‚¢
- åˆ†å²é–“ã®é–¢ä¿‚æ€§
- æœ€é©ãƒ‘ã‚¹ã®ç‰¹å®š
- æœ€çµ‚çš„ãªè§£æ±ºç­–

å˜ãªã‚‹ç·šå½¢æ€è€ƒã§ã¯ãªãã€ä½“ç³»çš„ãªæ¢ç´¢ã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚"""
            
            user_content = f"Goal: {goal}"
            
            messages = [
                EasyInputMessageParam(role="system", content=system_prompt),
                EasyInputMessageParam(
                    role="user",
                    content=[
                        ResponseInputTextParam(
                            type="input_text",
                            text=user_content
                        )
                    ]
                )
            ]
            
            with st.spinner("Tree of Thought æ¢ç´¢ä¸­..."):
                response = self.client.responses.create(
                    model=self.model,
                    input=messages
                )
            
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜
            st.session_state[f"tree_response_{self.safe_key}"] = response
            st.success("âœ… Tree of Thought æ¢ç´¢å®Œäº†")
            st.rerun()
            
        except Exception as e:
            st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            if config.get("experimental.debug_mode", False):
                st.exception(e)
    
    def _display_tree_results(self):
        """Tree of Thought çµæœã®è¡¨ç¤º"""
        if f"tree_response_{self.safe_key}" in st.session_state:
            response = st.session_state[f"tree_response_{self.safe_key}"]
            st.subheader("ğŸ¤– Tree of Thought çµæœ")
            ResponseProcessorUI.display_response(response)


class ProsConsDecisionDemo(BaseDemo):
    """è³›å¦æ¯”è¼ƒæ±ºå®šï¼ˆPros-Cons-Decisionï¼‰ãƒ‡ãƒ¢"""

    def run_demo(self):
        """è³›å¦æ¯”è¼ƒæ±ºå®šãƒ‡ãƒ¢ã®å®Ÿè¡Œ"""
        st.write("## å®Ÿè£…ä¾‹: Pros-Cons-Decision æ¨è«–")
        st.write("ãƒ¡ãƒªãƒƒãƒˆãƒ»ãƒ‡ãƒ¡ãƒªãƒƒãƒˆã‚’æ¯”è¼ƒã—ã¦åˆç†çš„ã«æ±ºå®šã™ã‚‹æ¨è«–ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å®Ÿè£…ã—ã¾ã™ã€‚")
        
        # å®Ÿè£…ä¾‹ã‚µãƒ³ãƒ—ãƒ«è¡¨ç¤º
        with st.expander("ğŸ“‹ å®Ÿè£…ä¾‹ã‚³ãƒ¼ãƒ‰", expanded=False):
            st.code("""
# Pros-Cons-Decision æ¨è«–ã®å®Ÿè£…ä¾‹
from openai import OpenAI
from openai.types.responses import EasyInputMessageParam, ResponseInputTextParam

client = OpenAI()

system_prompt = '''ã‚ãªãŸã¯ãƒãƒ©ãƒ³ã‚¹ã®å–ã‚ŒãŸæ„æ€æ±ºå®šæ”¯æ´ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
ãƒ¡ãƒªãƒƒãƒˆã¨ãƒ‡ãƒ¡ãƒªãƒƒãƒˆã‚’ä½“ç³»çš„ã«ãƒªã‚¹ãƒˆã‚¢ãƒƒãƒ—ã—ã¦ãƒˆãƒ”ãƒƒã‚¯ã‚’åˆ†æã—ã€ç†æ€§çš„ãªæ±ºå®šã‚’ä¸‹ã—ã¾ã™ã€‚

ãƒ—ãƒ­ã‚»ã‚¹ï¼š
1. å°‘ãªãã¨ã‚‚3ã¤ã®å…·ä½“çš„ãªåˆ©ç‚¹ï¼ˆãƒ¡ãƒªãƒƒãƒˆï¼‰ã‚’ãƒªã‚¹ãƒˆ
2. å°‘ãªãã¨ã‚‚3ã¤ã®å…·ä½“çš„ãªæ¬ ç‚¹ï¼ˆãƒ‡ãƒ¡ãƒªãƒƒãƒˆï¼‰ã‚’ãƒªã‚¹ãƒˆ
3. å„ãƒã‚¤ãƒ³ãƒˆã®é‡è¦åº¦ã‚’é‡ã¿ä»˜ã‘
4. æ˜ç¢ºãªæ¨å¥¨ã‚’è¡Œã†
5. æ±ºå®šã®è©³ç´°ãªæ ¹æ‹ ã‚’æä¾›
6. æ±ºå®šã¸ã®ä¿¡é ¼åº¦ã‚’è©•ä¾¡ï¼ˆ0-1ï¼‰

æ˜ç¢ºãªã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’æ§‹é€ åŒ–ã—ã¦ãã ã•ã„ï¼š
- Pros:ï¼ˆç•ªå·ä»˜ããƒªã‚¹ãƒˆï¼‰
- Cons:ï¼ˆç•ªå·ä»˜ããƒªã‚¹ãƒˆï¼‰
- Decision:ï¼ˆæ˜ç¢ºãªæ¨å¥¨ï¼‰
- Rationale:ï¼ˆè©³ç´°ãªæ¨è«–ï¼‰
- Confidence:ï¼ˆ0-1ã‚¹ã‚³ã‚¢ï¼‰'''

messages = [
    EasyInputMessageParam(role="system", content=system_prompt),
    EasyInputMessageParam(
        role="user",
        content=[
            ResponseInputTextParam(
                type="input_text", 
                text="Topic: ãƒªãƒ¢ãƒ¼ãƒˆãƒ¯ãƒ¼ã‚¯ã¨ã‚ªãƒ•ã‚£ã‚¹å‡ºç¤¾ã€ã©ã¡ã‚‰ã‚’é¸ã¶ã¹ãã‹ï¼Ÿ\\nPerspective: ä¸€èˆ¬çš„"
            )
        ]
    )
]

response = client.responses.create(model=model, input=messages)
            """, language="python")
        
        # å…¥åŠ›ã‚¨ãƒªã‚¢
        st.subheader("ğŸ“¤ å…¥åŠ›")
        
        topic = st.text_area(
            "æ„æ€æ±ºå®šã—ãŸã„ãƒˆãƒ”ãƒƒã‚¯",
            value="ãƒªãƒ¢ãƒ¼ãƒˆãƒ¯ãƒ¼ã‚¯ã¨ã‚ªãƒ•ã‚£ã‚¹å‡ºç¤¾ã€ã©ã¡ã‚‰ã‚’é¸ã¶ã¹ãã‹ï¼Ÿ",
            height=config.get("ui.text_area_height", 75),
            key=f"topic_{self.safe_key}"
        )
        
        perspective = st.selectbox(
            "è¦–ç‚¹",
            ["ä¸€èˆ¬çš„", "çµŒå–¶è€…", "å¾“æ¥­å“¡", "æŠ€è¡“è€…"],
            help="ã©ã®ç«‹å ´ã‹ã‚‰åˆ¤æ–­ã™ã‚‹ã‹",
            key=f"perspective_{self.safe_key}"
        )
        
        if st.button("âš–ï¸ è³›å¦æ¯”è¼ƒæ±ºå®šã‚’å®Ÿè¡Œ", key=f"submit_{self.safe_key}"):
            if topic:
                self._process_pros_cons_decision(topic, perspective)
        
        # çµæœè¡¨ç¤º
        self._display_decision_results()
    
    def _process_pros_cons_decision(self, topic: str, perspective: str):
        """è³›å¦æ¯”è¼ƒæ±ºå®šã®å‡¦ç†"""
        try:
            system_prompt = """ã‚ãªãŸã¯ãƒãƒ©ãƒ³ã‚¹ã®å–ã‚ŒãŸæ„æ€æ±ºå®šæ”¯æ´ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚
ãƒ¡ãƒªãƒƒãƒˆã¨ãƒ‡ãƒ¡ãƒªãƒƒãƒˆã‚’ä½“ç³»çš„ã«ãƒªã‚¹ãƒˆã‚¢ãƒƒãƒ—ã—ã¦ãƒˆãƒ”ãƒƒã‚¯ã‚’åˆ†æã—ã€ç†æ€§çš„ãªæ±ºå®šã‚’ä¸‹ã—ã¾ã™ã€‚

ãƒ—ãƒ­ã‚»ã‚¹ï¼š
1. å°‘ãªãã¨ã‚‚3ã¤ã®å…·ä½“çš„ãªåˆ©ç‚¹ï¼ˆãƒ¡ãƒªãƒƒãƒˆï¼‰ã‚’ãƒªã‚¹ãƒˆ
2. å°‘ãªãã¨ã‚‚3ã¤ã®å…·ä½“çš„ãªæ¬ ç‚¹ï¼ˆãƒ‡ãƒ¡ãƒªãƒƒãƒˆï¼‰ã‚’ãƒªã‚¹ãƒˆ
3. å„ãƒã‚¤ãƒ³ãƒˆã®é‡è¦åº¦ã‚’é‡ã¿ä»˜ã‘
4. æ˜ç¢ºãªæ¨å¥¨ã‚’è¡Œã†
5. æ±ºå®šã®è©³ç´°ãªæ ¹æ‹ ã‚’æä¾›
6. æ±ºå®šã¸ã®ä¿¡é ¼åº¦ã‚’è©•ä¾¡ï¼ˆ0-1ï¼‰

æ˜ç¢ºãªã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’æ§‹é€ åŒ–ã—ã¦ãã ã•ã„ï¼š
- Pros:ï¼ˆç•ªå·ä»˜ããƒªã‚¹ãƒˆï¼‰
- Cons:ï¼ˆç•ªå·ä»˜ããƒªã‚¹ãƒˆï¼‰
- Decision:ï¼ˆæ˜ç¢ºãªæ¨å¥¨ï¼‰
- Rationale:ï¼ˆè©³ç´°ãªæ¨è«–ï¼‰
- Confidence:ï¼ˆ0-1ã‚¹ã‚³ã‚¢ï¼‰

å®¢è¦³çš„ã§ã€è¤‡æ•°ã®è¦–ç‚¹ã‚’è€ƒæ…®ã—ã€è¨¼æ‹ ã«åŸºã¥ã„ã¦æ±ºå®šã—ã¦ãã ã•ã„ã€‚"""
            
            user_content = f"Topic: {topic}\nPerspective: {perspective}"
            
            messages = [
                EasyInputMessageParam(role="system", content=system_prompt),
                EasyInputMessageParam(
                    role="user",
                    content=[
                        ResponseInputTextParam(
                            type="input_text",
                            text=user_content
                        )
                    ]
                )
            ]
            
            with st.spinner("è³›å¦æ¯”è¼ƒæ±ºå®šä¸­..."):
                response = self.client.responses.create(
                    model=self.model,
                    input=messages
                )
            
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜
            st.session_state[f"decision_response_{self.safe_key}"] = response
            st.success("âœ… è³›å¦æ¯”è¼ƒæ±ºå®šå®Œäº†")
            st.rerun()
            
        except Exception as e:
            st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            if config.get("experimental.debug_mode", False):
                st.exception(e)
    
    def _display_decision_results(self):
        """æ±ºå®šçµæœã®è¡¨ç¤º"""
        if f"decision_response_{self.safe_key}" in st.session_state:
            response = st.session_state[f"decision_response_{self.safe_key}"]
            st.subheader("ğŸ¤– è³›å¦æ¯”è¼ƒæ±ºå®šçµæœ")
            ResponseProcessorUI.display_response(response)


class PlanExecuteReflectDemo(BaseDemo):
    """è¨ˆç”»å®Ÿè¡ŒæŒ¯ã‚Šè¿”ã‚Šï¼ˆPlan-Execute-Reflectï¼‰ãƒ‡ãƒ¢"""

    def run_demo(self):
        """è¨ˆç”»å®Ÿè¡ŒæŒ¯ã‚Šè¿”ã‚Šãƒ‡ãƒ¢ã®å®Ÿè¡Œ"""
        st.write("## å®Ÿè£…ä¾‹: Plan-Execute-Reflect æ¨è«–")
        st.write("è¨ˆç”»ãƒ»å®Ÿè¡Œãƒ»æŒ¯ã‚Šè¿”ã‚Šã®ãƒ«ãƒ¼ãƒ—ã§ç¶™ç¶šæ”¹å–„ã™ã‚‹æ¨è«–ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å®Ÿè£…ã—ã¾ã™ã€‚")
        
        # å®Ÿè£…ä¾‹ã‚µãƒ³ãƒ—ãƒ«è¡¨ç¤º
        with st.expander("ğŸ“‹ å®Ÿè£…ä¾‹ã‚³ãƒ¼ãƒ‰", expanded=False):
            st.code("""
# Plan-Execute-Reflect æ¨è«–ã®å®Ÿè£…ä¾‹
from openai import OpenAI
from openai.types.responses import EasyInputMessageParam, ResponseInputTextParam

client = OpenAI()

system_prompt = '''ã‚ãªãŸã¯Plan-Execute-Reflectæ”¹å–„ãƒ«ãƒ¼ãƒ—ã‚’å®Ÿè£…ã™ã‚‹AIã§ã™ã€‚

ãƒ—ãƒ­ã‚»ã‚¹ï¼š
1. PLAN: ç›®æ¨™ã®ãŸã‚ã®3-5å€‹ã®å…·ä½“çš„ã§å®Ÿè¡Œå¯èƒ½ãªã‚¹ãƒ†ãƒƒãƒ—ã‚’ä½œæˆ
2. EXECUTE: å®Ÿè¡Œã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆã—ã€ç¾å®Ÿçš„ãªçµæœ/èª²é¡Œã‚’æ–‡æ›¸åŒ–
3. REFLECT: ä½•ãŒã†ã¾ãã„ãã€ä½•ãŒã†ã¾ãã„ã‹ãšã€ãªãœã‹ã‚’åˆ†æ
4. IMPROVE: æŒ¯ã‚Šè¿”ã‚Šã«åŸºã¥ã„ã¦æ”¹å–„ã•ã‚ŒãŸè¨ˆç”»ã‚’ä½œæˆ
5. LEARN: å°†æ¥ã®å¿œç”¨ã®ãŸã‚ã®é‡è¦ãªæ•™è¨“ã‚’æŠ½å‡º

æ˜ç¢ºãªã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’æ§‹é€ åŒ–ã—ã¦ãã ã•ã„ï¼š
- Initial Plan:ï¼ˆç•ªå·ä»˜ãã®å®Ÿè¡Œå¯èƒ½ã‚¹ãƒ†ãƒƒãƒ—ï¼‰
- Execution Results:ï¼ˆçµæœã®ç¾å®Ÿçš„ãªã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰
- Reflections:ï¼ˆæˆåŠŸã¨å¤±æ•—ã®åˆ†æï¼‰
- Improved Plan:ï¼ˆå­¦ç¿’ã«åŸºã¥ãä¿®æ­£ã•ã‚ŒãŸã‚¹ãƒ†ãƒƒãƒ—ï¼‰
- Lessons Learned:ï¼ˆå°†æ¥ã®ãŸã‚ã®é‡è¦ãªæ´å¯Ÿï¼‰
- Success Probability:ï¼ˆæ”¹å–„ã•ã‚ŒãŸè¨ˆç”»ã®0-1æ¨å®šï¼‰

èª²é¡Œã«ã¤ã„ã¦ç¾å®Ÿçš„ã§ã€æ”¹å–„ã«ã¤ã„ã¦å…·ä½“çš„ã«ã—ã¦ãã ã•ã„ã€‚'''

messages = [
    EasyInputMessageParam(role="system", content=system_prompt),
    EasyInputMessageParam(
        role="user",
        content=[
            ResponseInputTextParam(
                type="input_text", 
                text="Objective: 3é€±é–“ä»¥å†…ã«ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã‚¹ã‚­ãƒ«ã‚’å‘ä¸Šã•ã›ã¦Webã‚¢ãƒ—ãƒªã‚’å®Œæˆã•ã›ã‚‹\\nComplexity Level: æ¨™æº–"
            )
        ]
    )
]

response = client.responses.create(model=model, input=messages)
            """, language="python")
        
        # å…¥åŠ›ã‚¨ãƒªã‚¢
        st.subheader("ğŸ“¤ å…¥åŠ›")
        
        objective = st.text_area(
            "ç›®æ¨™ï¼ˆé”æˆã—ãŸã„ã“ã¨ï¼‰",
            value="3é€±é–“ä»¥å†…ã«ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ã‚¹ã‚­ãƒ«ã‚’å‘ä¸Šã•ã›ã¦Webã‚¢ãƒ—ãƒªã‚’å®Œæˆã•ã›ã‚‹",
            height=config.get("ui.text_area_height", 75),
            key=f"objective_{self.safe_key}"
        )
        
        complexity = st.selectbox(
            "è¤‡é›‘ã•",
            ["ã‚·ãƒ³ãƒ—ãƒ«", "æ¨™æº–", "è¤‡é›‘"],
            index=1,
            help="ç›®æ¨™ã®è¤‡é›‘ã•ãƒ¬ãƒ™ãƒ«",
            key=f"complexity_{self.safe_key}"
        )
        
        if st.button("ğŸ”„ Plan-Execute-Reflect ã‚’å®Ÿè¡Œ", key=f"submit_{self.safe_key}"):
            if objective:
                self._process_plan_execute_reflect(objective, complexity)
        
        # çµæœè¡¨ç¤º
        self._display_reflect_results()
    
    def _process_plan_execute_reflect(self, objective: str, complexity: str):
        """Plan-Execute-Reflect ã®å‡¦ç†"""
        try:
            system_prompt = """ã‚ãªãŸã¯Plan-Execute-Reflectæ”¹å–„ãƒ«ãƒ¼ãƒ—ã‚’å®Ÿè£…ã™ã‚‹AIã§ã™ã€‚

ãƒ—ãƒ­ã‚»ã‚¹ï¼š
1. PLAN: ç›®æ¨™ã®ãŸã‚ã®3-5å€‹ã®å…·ä½“çš„ã§å®Ÿè¡Œå¯èƒ½ãªã‚¹ãƒ†ãƒƒãƒ—ã‚’ä½œæˆ
2. EXECUTE: å®Ÿè¡Œã‚’ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆã—ã€ç¾å®Ÿçš„ãªçµæœ/èª²é¡Œã‚’æ–‡æ›¸åŒ–
3. REFLECT: ä½•ãŒã†ã¾ãã„ãã€ä½•ãŒã†ã¾ãã„ã‹ãšã€ãªãœã‹ã‚’åˆ†æ
4. IMPROVE: æŒ¯ã‚Šè¿”ã‚Šã«åŸºã¥ã„ã¦æ”¹å–„ã•ã‚ŒãŸè¨ˆç”»ã‚’ä½œæˆ
5. LEARN: å°†æ¥ã®å¿œç”¨ã®ãŸã‚ã®é‡è¦ãªæ•™è¨“ã‚’æŠ½å‡º

æ˜ç¢ºãªã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’æ§‹é€ åŒ–ã—ã¦ãã ã•ã„ï¼š
- Initial Plan:ï¼ˆç•ªå·ä»˜ãã®å®Ÿè¡Œå¯èƒ½ã‚¹ãƒ†ãƒƒãƒ—ï¼‰
- Execution Results:ï¼ˆçµæœã®ç¾å®Ÿçš„ãªã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ï¼‰
- Reflections:ï¼ˆæˆåŠŸã¨å¤±æ•—ã®åˆ†æï¼‰
- Improved Plan:ï¼ˆå­¦ç¿’ã«åŸºã¥ãä¿®æ­£ã•ã‚ŒãŸã‚¹ãƒ†ãƒƒãƒ—ï¼‰
- Lessons Learned:ï¼ˆå°†æ¥ã®ãŸã‚ã®é‡è¦ãªæ´å¯Ÿï¼‰
- Success Probability:ï¼ˆæ”¹å–„ã•ã‚ŒãŸè¨ˆç”»ã®0-1æ¨å®šï¼‰

èª²é¡Œã«ã¤ã„ã¦ç¾å®Ÿçš„ã§ã€æ”¹å–„ã«ã¤ã„ã¦å…·ä½“çš„ã«ã—ã¦ãã ã•ã„ã€‚"""
            
            user_content = f"Objective: {objective}\nComplexity Level: {complexity}"
            
            messages = [
                EasyInputMessageParam(role="system", content=system_prompt),
                EasyInputMessageParam(
                    role="user",
                    content=[
                        ResponseInputTextParam(
                            type="input_text",
                            text=user_content
                        )
                    ]
                )
            ]
            
            with st.spinner("Plan-Execute-Reflect å®Ÿè¡Œä¸­..."):
                response = self.client.responses.create(
                    model=self.model,
                    input=messages
                )
            
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜
            st.session_state[f"reflect_response_{self.safe_key}"] = response
            st.success("âœ… Plan-Execute-Reflect å®Œäº†")
            st.rerun()
            
        except Exception as e:
            st.error(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
            if config.get("experimental.debug_mode", False):
                st.exception(e)
    
    def _display_reflect_results(self):
        """æŒ¯ã‚Šè¿”ã‚Šçµæœã®è¡¨ç¤º"""
        if f"reflect_response_{self.safe_key}" in st.session_state:
            response = st.session_state[f"reflect_response_{self.safe_key}"]
            st.subheader("ğŸ¤– Plan-Execute-Reflect çµæœ")
            ResponseProcessorUI.display_response(response)


# ==================================================
# ãƒ‡ãƒ¢ç®¡ç†ã‚¯ãƒ©ã‚¹ï¼ˆçµ±ä¸€åŒ–ç‰ˆï¼‰
# ==================================================
class DemoManager:
    """ãƒ‡ãƒ¢ç®¡ç†ã‚¯ãƒ©ã‚¹ï¼ˆçµ±ä¸€åŒ–ç‰ˆï¼‰"""
    
    def __init__(self):
        self.demos = {
            "æ®µéšçš„æ¨è«–ï¼ˆStep-by-Stepï¼‰": StepByStepReasoningDemo,
            "ä»®èª¬æ¤œè¨¼æ¨è«–ï¼ˆHypothesis-Testï¼‰": HypothesisTestDemo,
            "æ€è€ƒã®æœ¨ï¼ˆTree of Thoughtï¼‰": TreeOfThoughtDemo,
            "è³›å¦æ¯”è¼ƒæ±ºå®šï¼ˆPros-Cons-Decisionï¼‰": ProsConsDecisionDemo,
            "è¨ˆç”»å®Ÿè¡ŒæŒ¯ã‚Šè¿”ã‚Šï¼ˆPlan-Execute-Reflectï¼‰": PlanExecuteReflectDemo,
        }
    
    def get_demo_list(self) -> List[str]:
        """ãƒ‡ãƒ¢ãƒªã‚¹ãƒˆã®å–å¾—"""
        return list(self.demos.keys())
    
    def run_demo(self, demo_name: str, selected_model: str):
        """é¸æŠã•ã‚ŒãŸãƒ‡ãƒ¢ã®å®Ÿè¡Œ"""
        if demo_name in self.demos:
            demo_class = self.demos[demo_name]
            demo_instance = demo_class(demo_name)
            demo_instance.execute(selected_model)
        else:
            st.error(f"ä¸æ˜ãªãƒ‡ãƒ¢: {demo_name}")


# ==================================================
# ãƒ¡ã‚¤ãƒ³é–¢æ•°ï¼ˆçµ±ä¸€åŒ–ç‰ˆï¼‰
# ==================================================
def main():
    """ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ï¼ˆçµ±ä¸€åŒ–ç‰ˆï¼‰"""
    # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
    SessionStateManager.init_session_state()
    
    # ãƒ‡ãƒ¢ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã®åˆæœŸåŒ–
    demo_manager = DemoManager()
    
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼: a10_00ã®é †åºã«çµ±ä¸€ï¼ˆãƒ‡ãƒ¢é¸æŠ â†’ ãƒ¢ãƒ‡ãƒ«é¸æŠ â†’ æƒ…å ±ãƒ‘ãƒãƒ«ï¼‰
    with st.sidebar:
        # 1. ãƒ‡ãƒ¢é¸æŠ
        demo_name = st.radio(
            "[a06_reasoning_chain_of_thought.py] ãƒ‡ãƒ¢é¸æŠ",
            demo_manager.get_demo_list(),
            key="demo_selection"
        )
        
        # 2. ãƒ¢ãƒ‡ãƒ«é¸æŠï¼ˆãƒ‡ãƒ¢é¸æŠã®ç›´å¾Œï¼‰
        selected_model = UIHelper.select_model("model_selection")
        
        # 3. æƒ…å ±ãƒ‘ãƒãƒ«
        setup_sidebar_panels(selected_model)
    
    # ãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢ï¼ˆ1æ®µæ§‹æˆã«çµ±ä¸€ï¼‰
    # é¸æŠã•ã‚ŒãŸãƒ‡ãƒ¢ã‚’å®Ÿè¡Œ
    try:
        demo_manager.run_demo(demo_name, selected_model)
    except Exception as e:
        st.error(f"ãƒ‡ãƒ¢ã®å®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        if config.get("experimental.debug_mode", False):
            st.exception(e)


if __name__ == "__main__":
    main()

# streamlit run a06_reasoning_chain_of_thought.py --server.port=8506