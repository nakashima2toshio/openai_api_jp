# streamlit run a04_audio_speeches.py --server.port=8504
# --------------------------------------------------
# OpenAI Audio & Speech API ãƒ‡ãƒ¢ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
# Streamlitã‚’ä½¿ç”¨ã—ãŸã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ãªéŸ³å£°APIãƒ†ã‚¹ãƒˆãƒ„ãƒ¼ãƒ«
# çµ±ä¸€åŒ–æ”¹ä¿®ç‰ˆ: a10_00_responses_api.pyã®æ§‹æˆãƒ»æ§‹é€ ãƒ»ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãƒ»ã‚¨ãƒ©ãƒ¼å‡¦ç†ã®å®Œå…¨çµ±ä¸€
# --------------------------------------------------
import os
import sys
import asyncio
import base64
import time
import random
from io import BytesIO
from pathlib import Path
from abc import ABC, abstractmethod
from typing import Optional, List, Dict, Any, Union
import logging
import textwrap

import streamlit as st

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®è¨­å®š
BASE_DIR = Path(__file__).resolve().parent.parent
THIS_DIR = Path(__file__).resolve().parent

# PYTHONPATHã«è¦ªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’è¿½åŠ 
sys.path.insert(0, str(BASE_DIR))

# ãƒ˜ãƒ«ãƒ‘ãƒ¼ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆçµ±ä¸€åŒ–ï¼‰
try:
    from helper_st import (
        UIHelper as BaseUIHelper,
        MessageManagerUI, ResponseProcessorUI,
        SessionStateManager, error_handler_ui, timer_ui,
        InfoPanelManager as BaseInfoPanelManager,
        safe_streamlit_json,
    )
    from helper_api import (
        config, logger, TokenManager, OpenAIClient,
        EasyInputMessageParam, ResponseInputTextParam,
        ConfigManager, MessageManager, sanitize_key,
        error_handler, timer, get_default_messages,
        ResponseProcessor, format_timestamp
    )
except ImportError as e:
    st.error(f"ãƒ˜ãƒ«ãƒ‘ãƒ¼ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
    st.info("å¿…è¦ãªãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã™ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„: helper_st.py, helper_api.py")
    st.stop()

from openai import OpenAI, AsyncOpenAI
from openai.types.chat import (
    ChatCompletionSystemMessageParam,
    ChatCompletionUserMessageParam,
    ChatCompletionMessageParam,
)

# ãƒšãƒ¼ã‚¸è¨­å®š
def setup_page_config():
    """ãƒšãƒ¼ã‚¸è¨­å®šï¼ˆé‡è¤‡å®Ÿè¡Œã‚¨ãƒ©ãƒ¼å›é¿ï¼‰"""
    try:
        st.set_page_config(
            page_title=config.get("ui.page_title", "OpenAI Audio & Speech API Demo"),
            page_icon=config.get("ui.page_icon", "ğŸµ"),
            layout=config.get("ui.layout", "wide"),
            initial_sidebar_state="expanded"
        )
    except st.errors.StreamlitAPIException:
        pass

setup_page_config()

# ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®è¨­å®š
DATA_DIR = Path(config.get("paths.data", "data"))
DATA_DIR.mkdir(exist_ok=True)

# ==================================================
# å…±é€šUIé–¢æ•°ï¼ˆçµ±ä¸€åŒ–ç‰ˆï¼‰
# ==================================================
def setup_common_ui(demo_name: str) -> str:
    """å…±é€šUIè¨­å®šï¼ˆçµ±ä¸€åŒ–ç‰ˆï¼‰"""
    safe_key = sanitize_key(demo_name)
    st.write(f"# {demo_name}")

    # ãƒ¢ãƒ‡ãƒ«é¸æŠï¼ˆéŸ³å£°ç”¨ãƒ¢ãƒ‡ãƒ«é¸æŠï¼‰
    model = UIHelper.select_audio_model(f"model_{safe_key}")
    st.write("é¸æŠã—ãŸãƒ¢ãƒ‡ãƒ«:", model)
    return model

def setup_sidebar_panels(selected_model: str):
    """ã‚µã‚¤ãƒ‰ãƒãƒ¼ãƒ‘ãƒãƒ«ã®çµ±ä¸€è¨­å®šï¼ˆéŸ³å£°APIç”¨ï¼‰"""
    st.sidebar.markdown("### ğŸµ Audio API æƒ…å ±")  # â† expanded=False ã‚’å‰Šé™¤
    InfoPanelManager.show_audio_model_info(selected_model)
    InfoPanelManager.show_session_info()
    InfoPanelManager.show_performance_info()
    InfoPanelManager.show_audio_cost_info(selected_model)
    InfoPanelManager.show_debug_panel()
    InfoPanelManager.show_settings()

# ==================================================
# UIHelperæ‹¡å¼µï¼ˆéŸ³å£°ç”¨ï¼‰
# ==================================================
class UIHelper(BaseUIHelper):
    """UIHelperæ‹¡å¼µï¼ˆéŸ³å£°APIç”¨ï¼‰"""

    @staticmethod
    def select_audio_model(key: str = "audio_model_selection") -> str:
        """éŸ³å£°APIç”¨ãƒ¢ãƒ‡ãƒ«é¸æŠ"""
        audio_models = config.get("models.categories.audio", [
            "tts-1", "tts-1-hd", "gpt-4o-mini-tts",
            "whisper-1", "gpt-4o-transcribe"
        ])
        default_model = config.get("models.audio_default", "tts-1")
        default_index = audio_models.index(default_model) if default_model in audio_models else 0

        selected = st.sidebar.selectbox(
            "éŸ³å£°ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ",
            audio_models,
            index=default_index,
            key=key,
            help="åˆ©ç”¨ã™ã‚‹OpenAIéŸ³å£°ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„",
        )
        SessionStateManager.set_user_preference("selected_audio_model", selected)
        return selected

    @staticmethod
    def select_voice(key: str = "voice_selection") -> str:
        """éŸ³å£°é¸æŠUI"""
        voices = config.get("audio.voices", ["alloy", "nova", "echo", "onyx", "shimmer"])
        return st.selectbox(
            "Voice",
            voices,
            index=0,
            key=key,
            help="éŸ³å£°ã®ç¨®é¡ã‚’é¸æŠã—ã¦ãã ã•ã„"
        )

    @staticmethod
    def create_audio_download_button(audio_data: bytes, filename: str, label: str = "ğŸ“¥ éŸ³å£°ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"):
        """éŸ³å£°ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ã®ä½œæˆ"""
        try:
            st.download_button(
                label=label,
                data=audio_data,
                file_name=filename,
                mime="audio/mp3",
                help=f"{filename}ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™"
            )
        except Exception as e:
            st.error(f"éŸ³å£°ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ä½œæˆã‚¨ãƒ©ãƒ¼: {e}")
            logger.error(f"Audio download button error: {e}")

# ==================================================
# InfoPanelManageræ‹¡å¼µï¼ˆéŸ³å£°ç”¨ï¼‰
# ==================================================
class InfoPanelManager(BaseInfoPanelManager):
    """InfoPanelManageræ‹¡å¼µï¼ˆéŸ³å£°APIç”¨ï¼‰"""

    @staticmethod
    def show_audio_model_info(selected_model: str):
        with st.sidebar.expander("ğŸµ éŸ³å£°ãƒ¢ãƒ‡ãƒ«æƒ…å ±", expanded=False):
            if selected_model.startswith("tts-") or selected_model.startswith("gpt-4o-mini-tts"):
                st.info("ğŸ¤ Text-to-Speech ãƒ¢ãƒ‡ãƒ«")
                model_info = {
                    "tts-1": "é€Ÿåº¦æœ€é©åŒ–ãƒ¢ãƒ‡ãƒ«",
                    "tts-1-hd": "é«˜å“è³ªãƒ¢ãƒ‡ãƒ«",
                    "gpt-4o-mini-tts": "GPT-4oæ­è¼‰TTS"
                }
                st.write(f"**ç‰¹å¾´**: {model_info.get(selected_model, 'ä¸æ˜')}")
                st.write("**å‡ºåŠ›**: MP3")
                st.write("**æœ€å¤§æ–‡å­—æ•°**: 4,096æ–‡å­—")
            else:
                st.info("ğŸ§ Speech-to-Text ãƒ¢ãƒ‡ãƒ«")
                model_info = {
                    "whisper-1": "æ¨™æº–éŸ³å£°èªè­˜",
                    "gpt-4o-transcribe": "é«˜ç²¾åº¦éŸ³å£°èªè­˜"
                }
                st.write(f"**ç‰¹å¾´**: {model_info.get(selected_model, 'ä¸æ˜')}")
                st.write("**å…¥åŠ›**: MP3, WAV, M4A")
                st.write("**æœ€å¤§ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º**: 25MB")

    @staticmethod
    def show_audio_cost_info(selected_model: str):
        with st.sidebar.expander("ğŸ’° éŸ³å£°APIæ–™é‡‘", expanded=False):
            if "tts" in selected_model:
                st.write("**TTSæ–™é‡‘ (1000æ–‡å­—ã‚ãŸã‚Š)**")
                tts_pricing = {"tts-1": "$0.015", "tts-1-hd": "$0.030", "gpt-4o-mini-tts": "$0.025"}
                current_price = tts_pricing.get(selected_model, "ä¸æ˜")
                st.write(f"- {selected_model}: {current_price}")
                char_count = st.number_input("æ–‡å­—æ•°", min_value=1, value=100, step=10, key="tts_char_count")
                if selected_model in tts_pricing:
                    price = float(tts_pricing[selected_model].replace("$", ""))
                    cost = (char_count / 1000) * price
                    st.write(f"**æ¨å®šã‚³ã‚¹ãƒˆ**: ${cost:.6f}")
            else:
                st.write("**STTæ–™é‡‘ (åˆ†ã‚ãŸã‚Š)**")
                st.write("- whisper-1: $0.006")
                st.write("- gpt-4o-transcribe: $0.010")
                duration_minutes = st.number_input("éŸ³å£°æ™‚é–“ï¼ˆåˆ†ï¼‰", min_value=0.1, value=1.0, step=0.1, key="stt_duration")
                stt_pricing = {"whisper-1": 0.006, "gpt-4o-transcribe": 0.010}
                if selected_model in stt_pricing:
                    cost = duration_minutes * stt_pricing[selected_model]
                    st.write(f"**æ¨å®šã‚³ã‚¹ãƒˆ**: ${cost:.6f}")

# ==================================================
# åŸºåº•ã‚¯ãƒ©ã‚¹ï¼ˆçµ±ä¸€åŒ–ç‰ˆï¼‰
# ==================================================
class BaseDemo(ABC):
    """ãƒ‡ãƒ¢æ©Ÿèƒ½ã®åŸºåº•ã‚¯ãƒ©ã‚¹ï¼ˆéŸ³å£°ç”¨çµ±ä¸€åŒ–ç‰ˆï¼‰"""

    def __init__(self, demo_name: str):
        self.demo_name = demo_name
        self.config = ConfigManager("config.yml")
        try:
            self.client = OpenAIClient()
            self.openai_client = OpenAI()
            self.async_client = AsyncOpenAI()
        except Exception as e:
            st.error(f"OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            st.stop()

        self.safe_key = sanitize_key(demo_name)
        self.message_manager = MessageManagerUI(f"messages_{self.safe_key}")
        self.model = None

        SessionStateManager.init_session_state()
        self._initialize_session_state()

    def _initialize_session_state(self):
        session_key = f"demo_state_{self.safe_key}"
        if session_key not in st.session_state:
            st.session_state[session_key] = {
                'initialized': True,
                'model': self.config.get("models.audio_default", "tts-1"),
                'execution_count': 0,
                'last_audio_file': None
            }

    def get_model(self) -> str:
        return st.session_state.get(f"model_{self.safe_key}", config.get("models.audio_default", "tts-1"))

    def initialize(self):
        self.model = setup_common_ui(self.demo_name)
        setup_sidebar_panels(self.model)

    def handle_error(self, e: Exception):
        lang = config.get("i18n.default_language", "ja")
        error_msg = config.get(f"error_messages.{lang}.general_error", "ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ")
        st.error(f"{error_msg}: {str(e)}")
        if config.get("experimental.debug_mode", False):
            with st.expander("ğŸ”§ è©³ç´°ã‚¨ãƒ©ãƒ¼æƒ…å ±", expanded=False):
                st.exception(e)

    @error_handler_ui
    @timer_ui
    def safe_audio_api_call(self, api_func: callable, *args, **kwargs):
        max_retries = config.get("api.max_retries", 3)
        delay = config.get("api.retry_delay", 1)
        for attempt in range(max_retries):
            try:
                return api_func(*args, **kwargs)
            except Exception as e:
                if attempt == max_retries - 1:
                    raise e
                logger.warning(f"éŸ³å£°APIå‘¼ã³å‡ºã—å¤±æ•— (è©¦è¡Œ {attempt + 1}/{max_retries}): {e}")
                time.sleep(delay)
                delay *= 2 + random.random()

    @abstractmethod
    def run(self):
        pass

# ==================================================
# Text to Speech ãƒ‡ãƒ¢ï¼ˆçµ±ä¸€åŒ–ç‰ˆï¼‰
# ==================================================
class TextToSpeechDemo(BaseDemo):
    """Text to Speech API ã®ãƒ‡ãƒ¢ï¼ˆçµ±ä¸€åŒ–ç‰ˆï¼‰"""

    @error_handler_ui
    @timer_ui
    def run(self):
        self.initialize()

        st.write("## Text-to-Speech ãƒ‡ãƒ¢")
        st.write("ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰éŸ³å£°ã‚’ç”Ÿæˆã—ã¾ã™ã€‚")

        # å…¥åŠ›ã‚¨ãƒªã‚¢
        st.subheader("ğŸ“¤ å…¥åŠ›")
        
        # ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›
        text_input = st.text_area(
            "éŸ³å£°åŒ–ã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼š",
            value="ã“ã‚“ã«ã¡ã¯ã€OpenAI Text-to-Speech APIã®ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§ã™ã€‚",
            height=100,
            max_chars=4096,
            key=f"tts_text_{self.safe_key}"
        )
        
        # éŸ³å£°è¨­å®š
        col1, col2, col3 = st.columns(3)
        with col1:
            voice = UIHelper.select_voice(f"voice_{self.safe_key}")
        with col2:
            speed = st.slider(
                "é€Ÿåº¦",
                min_value=0.25,
                max_value=4.0,
                value=1.0,
                step=0.25,
                key=f"speed_{self.safe_key}"
            )
        with col3:
            response_format = st.selectbox(
                "å‡ºåŠ›å½¢å¼",
                ["mp3", "opus", "aac", "flac"],
                key=f"format_{self.safe_key}"
            )
        
        # ç”Ÿæˆãƒœã‚¿ãƒ³
        if st.button("ğŸµ éŸ³å£°ã‚’ç”Ÿæˆ", key=f"generate_{self.safe_key}"):
            if text_input:
                self._generate_speech(text_input, voice, speed, response_format)
    
    def _generate_speech(self, text: str, voice: str, speed: float, response_format: str):
        """éŸ³å£°ç”Ÿæˆã®å®Ÿè¡Œ"""
        try:
            # å®Ÿè¡Œæ™‚é–“ã®è¨ˆæ¸¬é–‹å§‹
            start_time = time.time()
            
            # ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜
            st.session_state[f"tts_text_{self.safe_key}"] = text
            st.session_state[f"tts_voice_{self.safe_key}"] = voice
            
            with st.spinner("éŸ³å£°ã‚’ç”Ÿæˆä¸­..."):
                response = self.openai_client.audio.speech.create(
                    model=self.model,
                    voice=voice,
                    input=text,
                    speed=speed,
                    response_format=response_format
                )
            
            # å®Ÿè¡Œæ™‚é–“ã®è¨ˆç®—
            generation_time = time.time() - start_time
            
            # éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            audio_data = response.content
            
            st.success("éŸ³å£°ã‚’ç”Ÿæˆã—ã¾ã—ãŸ")
            st.subheader("ğŸµ ç”Ÿæˆçµæœ")
            
            # ãƒ¡ã‚¤ãƒ³ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã¨å³ãƒšã‚¤ãƒ³
            col1, col2 = st.columns([3, 1])
            
            with col1:
                # éŸ³å£°ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼
                st.audio(audio_data, format=f"audio/{response_format}")
                
                # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
                filename = f"speech_{int(time.time())}.{response_format}"
                UIHelper.create_audio_download_button(
                    audio_data, 
                    filename,
                    "ğŸ“¥ éŸ³å£°ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"
                )
                
                # ç”Ÿæˆãƒ†ã‚­ã‚¹ãƒˆã®è¡¨ç¤º
                with st.expander("ç”Ÿæˆã—ãŸãƒ†ã‚­ã‚¹ãƒˆ"):
                    st.write(text)
                
            with col2:
                # æƒ…å ±ãƒ‘ãƒãƒ«
                st.write("**ğŸ“Š ç”Ÿæˆæƒ…å ±**")
                
                # ãƒ¢ãƒ‡ãƒ«æƒ…å ±
                st.metric("ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«", self.model.upper())
                
                # ç”Ÿæˆæ™‚é–“
                st.metric("ç”Ÿæˆæ™‚é–“", f"{generation_time:.2f}ç§’")
                
                # éŸ³å£°è¨­å®š
                st.write("**ğŸµ éŸ³å£°è¨­å®š**")
                st.write(f"Voice: {voice}")
                st.write(f"é€Ÿåº¦: {speed}x")
                st.write(f"å½¢å¼: {response_format}")
                
                # ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±
                st.write("**ğŸ“ ãƒ†ã‚­ã‚¹ãƒˆæƒ…å ±**")
                st.metric("æ–‡å­—æ•°", len(text))
                
                # ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º
                file_size = len(audio_data) / 1024  # KBå˜ä½
                st.metric("ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º", f"{file_size:.1f} KB")
                
                # ã‚³ã‚¹ãƒˆæ¨å®š
                st.write("**ğŸ’° ã‚³ã‚¹ãƒˆæ¨å®š**")
                tts_pricing = {
                    "tts-1": 0.015,
                    "tts-1-hd": 0.030,
                    "gpt-4o-mini-tts": 0.025
                }
                if self.model in tts_pricing:
                    cost = (len(text) / 1000) * tts_pricing[self.model]
                    st.write(f"${cost:.6f}")
            
        except Exception as e:
            st.error(f"éŸ³å£°ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}")
            if config.get("experimental.debug_mode", False):
                st.exception(e)


# ==================================================
# ãƒ‡ãƒ¢ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ï¼ˆçµ±ä¸€åŒ–ç‰ˆï¼‰
# ==================================================
class AudioDemoManager:
    """éŸ³å£°ãƒ‡ãƒ¢ã®ç®¡ç†ã‚¯ãƒ©ã‚¹ï¼ˆçµ±ä¸€åŒ–ç‰ˆï¼‰"""

    def __init__(self):
        self.config = ConfigManager("config.yml")
        self.demos = self._initialize_demos()

    def _initialize_demos(self) -> Dict[str, BaseDemo]:
        return {
            "Text to Speech": TextToSpeechDemo("Text to Speech"),
        }

    @error_handler_ui
    @timer_ui
    def run(self):
        try:
            SessionStateManager.init_session_state()
            demo_name = st.sidebar.radio("[a04_audio_speeches.py] Audio Demo", list(self.demos.keys()), key="audio_demo_selection")

            if "current_audio_demo" not in st.session_state:
                st.session_state.current_audio_demo = demo_name
            elif st.session_state.current_audio_demo != demo_name:
                st.session_state.current_audio_demo = demo_name

            demo = self.demos.get(demo_name)
            if demo:
                demo.run()
            else:
                st.error(f"ãƒ‡ãƒ¢ '{demo_name}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

            self._display_footer()
        except Exception as e:
            st.error(f"ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®å®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
            logger.error(f"Audio application execution error: {e}")
            if config.get("experimental.debug_mode", False):
                with st.expander("ğŸ”§ è©³ç´°ã‚¨ãƒ©ãƒ¼æƒ…å ±", expanded=False):
                    st.exception(e)

    def _display_footer(self):
        st.sidebar.markdown("---")
        st.sidebar.markdown("### ğŸµ Audio API æƒ…å ±")
        with st.sidebar.expander("ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±"):
            audio_files = list(DATA_DIR.glob("*.mp3")) + list(DATA_DIR.glob("*.wav"))
            txt_files = list(DATA_DIR.glob("*.txt"))
            st.write(f"**ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª**: {DATA_DIR}")
            st.write(f"**éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«æ•°**: {len(audio_files)}")
            st.write(f"**ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«æ•°**: {len(txt_files)}")

        with st.sidebar.expander("ç¾åœ¨ã®è¨­å®š"):
            safe_streamlit_json({
                "data_directory": str(DATA_DIR),
                "audio_models": config.get("models.categories.audio"),
                "supported_formats": config.get("audio.supported_formats"),
                "debug_mode": config.get("experimental.debug_mode"),
            })

        st.sidebar.markdown("### ãƒãƒ¼ã‚¸ãƒ§ãƒ³")
        st.sidebar.markdown("- OpenAI Audio & Speech Demo v3.1 (çµ±ä¸€åŒ–ç‰ˆ)")
        st.sidebar.markdown("- Streamlit " + st.__version__)
        st.sidebar.markdown("### ãƒªãƒ³ã‚¯")
        st.sidebar.markdown("[OpenAI Audio API](https://platform.openai.com/docs/guides/speech-to-text)")
        st.sidebar.markdown("[Realtime API](https://platform.openai.com/docs/guides/realtime)")

# ==================================================
# ãƒ¡ã‚¤ãƒ³é–¢æ•°ï¼ˆçµ±ä¸€åŒ–ç‰ˆï¼‰
# ==================================================
def main():
    try:
        logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
        if not os.getenv("OPENAI_API_KEY"):
            st.error("ç’°å¢ƒå¤‰æ•° OPENAI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
            st.info("export OPENAI_API_KEY='your-api-key' ã‚’å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚")
            st.stop()

        SessionStateManager.init_session_state()
        manager = AudioDemoManager()
        manager.run()
    except Exception as e:
        st.error(f"ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®èµ·å‹•ã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
        logger.error(f"Audio application startup error: {e}")
        if config.get("experimental.debug_mode", False):
            with st.expander("ğŸ”§ è©³ç´°ã‚¨ãƒ©ãƒ¼æƒ…å ±", expanded=False):
                st.exception(e)

if __name__ == "__main__":
    main()

# streamlit run a04_audio_speeches.py --server.port=8504
