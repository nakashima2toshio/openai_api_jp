1. OpenAI API → Anthropic API 移植仕様書

2. エグゼクティブサマリー

3. 本文書は、OpenAI API を使用したアプリケーションを Anthropic API (Claude) へ移植するための技術仕様書です。両APIの主要な差異と、移植に必要な変更点を体系的にまとめています。

4. 移植難易度評価
   4.1. 全体難易度: 中程度
   4.2. 推定工数: 既存コードベースの規模により2-4週間
   4.3. 主要な変更箇所: API呼び出し形式、モデル名、一部機能の代替実装

5. 基本的なAPI構造の比較

6. クライアント初期化
   6.1. OpenAI
       from openai import OpenAI
       client = OpenAI(api_key="sk-...")
   
   6.2. Anthropic
       from anthropic import Anthropic
       client = Anthropic(api_key="sk-ant-...")
   
   6.3. 移植ポイント
       6.3.1. ライブラリ名とクライアントクラス名の変更
       6.3.2. APIキーのプレフィックスが異なる（sk- → sk-ant-）

7. 基本的なメッセージ送信
   7.1. OpenAI
       response = client.chat.completions.create(
           model="gpt-4",
           messages=[
               {"role": "system", "content": "You are a helpful assistant"},
               {"role": "user", "content": "Hello"}
           ]
       )
       result = response.choices[0].message.content
   
   7.2. Anthropic
       message = client.messages.create(
           model="claude-3-5-sonnet-20241022",
           system="You are a helpful assistant",  # システムメッセージは別パラメータ
           messages=[
               {"role": "user", "content": "Hello"}
           ],
           max_tokens=1024  # 必須パラメータ
       )
       result = message.content[0].text
   
   7.3. 主要な違い
       7.3.1. エンドポイント名: chat.completions.create → messages.create
       7.3.2. システムメッセージの扱い: messages配列内 → 独立したsystemパラメータ
       7.3.3. max_tokensが必須パラメータ
       7.3.4. レスポンス構造: choices[0].message.content → content[0].text

8. 機能別移植ガイド

9. 構造化出力 (Structured Outputs)
   9.1. OpenAI - response_format使用
       response = client.chat.completions.create(
           model="gpt-4",
           messages=messages,
           response_format={
               "type": "json_schema",
               "json_schema": schema
           }
       )
   
   9.2. Anthropic - Tool使用による実装
       tools = [{
           "name": "extract_data",
           "description": "Extract structured data",
           "input_schema": schema  # Pydantic model.model_json_schema()
       }]
       
       message = client.messages.create(
           model="claude-3-5-sonnet-20241022",
           max_tokens=1024,
           tools=tools,
           messages=messages
       )
       
       # Tool呼び出し結果から構造化データを取得
       if message.content[0].type == "tool_use":
           structured_data = message.content[0].input
   
   9.3. 移植ポイント
       9.3.1. OpenAIのresponse_format → AnthropicのTool機能で代替
       9.3.2. スキーマ定義方法は類似（JSON Schema形式）
       9.3.3. レスポンス処理ロジックの変更が必要

10. Function Calling / Tool Use
    10.1. OpenAI
        tools = [{
            "type": "function",
            "function": {
                "name": "get_weather",
                "description": "Get weather information",
                "parameters": {
                    "type": "object",
                    "properties": {
                        "location": {"type": "string"}
                    }
                }
            }
        }]
        
        response = client.chat.completions.create(
            model="gpt-4",
            messages=messages,
            tools=tools,
            tool_choice="auto"
        )
    
    10.2. Anthropic
        tools = [{
            "name": "get_weather",
            "description": "Get weather information",
            "input_schema": {
                "type": "object",
                "properties": {
                    "location": {"type": "string"}
                }
            }
        }]
        
        message = client.messages.create(
            model="claude-3-5-sonnet-20241022",
            max_tokens=1024,
            tools=tools,
            messages=messages
        )
    
    10.3. 移植ポイント
        10.3.1. Tool定義構造の簡素化（functionラッパー不要）
        10.3.2. parameters → input_schema
        10.3.3. tool_choiceパラメータは現在サポートされていない

11. 画像処理 (Vision)
    11.1. OpenAI
        messages = [{
            "role": "user",
            "content": [
                {"type": "text", "text": "What's in this image?"},
                {"type": "image_url", "image_url": {"url": image_url}}
            ]
        }]
    
    11.2. Anthropic
        messages = [{
            "role": "user",
            "content": [
                {"type": "text", "text": "What's in this image?"},
                {
                    "type": "image",
                    "source": {
                        "type": "base64",  # または "url"
                        "media_type": "image/jpeg",
                        "data": base64_data  # または "url": image_url
                    }
                }
            ]
        }]
    
    11.3. 移植ポイント
        11.3.1. 画像指定方法の変更: image_url → image.source
        11.3.2. media_typeの明示的な指定が必要
        11.3.3. Base64エンコーディングを推奨

12. ストリーミング
    12.1. OpenAI
        stream = client.chat.completions.create(
            model="gpt-4",
            messages=messages,
            stream=True
        )
        
        for chunk in stream:
            if chunk.choices[0].delta.content:
                print(chunk.choices[0].delta.content, end="")
    
    12.2. Anthropic
        with client.messages.stream(
            model="claude-3-5-sonnet-20241022",
            max_tokens=1024,
            messages=messages
        ) as stream:
            for chunk in stream:
                if chunk.type == "content_block_delta":
                    print(chunk.delta.text, end="")
    
    12.3. 移植ポイント
        12.3.1. ストリーミングメソッドが別: create(stream=True) → stream()
        12.3.2. コンテキストマネージャー（with文）の使用を推奨
        12.3.3. チャンクデータ構造の違い

13. 音声処理
    13.1. OpenAI
        # Text-to-Speech
        response = client.audio.speech.create(
            model="tts-1",
            voice="alloy",
            input="Hello world"
        )
        
        # Speech-to-Text
        transcription = client.audio.transcriptions.create(
            model="whisper-1",
            file=audio_file
        )
    
    13.2. Anthropic
        # Anthropic APIは音声処理を直接サポートしていない
        # 代替案：外部サービス（Whisper API等）との組み合わせ
        
        # Step 1: 外部サービスで音声処理
        transcription = external_whisper_api.transcribe(audio_file)
        
        # Step 2: テキストをClaude APIで処理
        message = client.messages.create(
            model="claude-3-5-sonnet-20241022",
            max_tokens=1024,
            messages=[{"role": "user", "content": transcription}]
        )
    
    13.3. 移植ポイント
        13.3.1. 重要: Anthropic APIは音声処理機能を持たない
        13.3.2. 外部音声処理サービスとの統合が必要
        13.3.3. アーキテクチャの再設計が必要な場合がある

14. モデル対応表
    14.1. 最高性能・推論重視
        14.1.1. OpenAI: gpt-5 (4段階の推論レベル)
        14.1.2. Anthropic: claude-4-opus
        14.1.3. 備考: GPT-5: 数学94.6%、コーディング74.9%精度
    
    14.2. 高性能・複雑なタスク
        14.2.1. OpenAI: gpt-4o, gpt-4-turbo
        14.2.2. Anthropic: claude-3-5-sonnet-20241022
        14.2.3. 備考: 汎用高性能モデル
    
    14.3. バランス型
        14.3.1. OpenAI: gpt-5-mini, gpt-3.5-turbo
        14.3.2. Anthropic: claude-3-haiku-20240307
        14.3.3. 備考: コスト効率重視
    
    14.4. 超軽量・高速処理
        14.4.1. OpenAI: gpt-5-nano
        14.4.2. Anthropic: claude-3-haiku
        14.4.3. 備考: 最速レスポンス
    
    14.5. 画像理解
        14.5.1. OpenAI: gpt-5, gpt-4o-vision
        14.5.2. Anthropic: claude-3-5-sonnet-20241022
        14.5.3. 備考: GPT-5: マルチモーダル84.2%精度
    
    14.6. 長文処理
        14.6.1. OpenAI: gpt-5 (272k入力)
        14.6.2. Anthropic: claude-3-5-sonnet (200k)
        14.6.3. 備考: GPT-5が最大コンテキスト
    
    14.7. コーディング
        14.7.1. OpenAI: gpt-5, gpt-4o
        14.7.2. Anthropic: claude-3-5-sonnet-20241022
        14.7.3. 備考: GPT-5: SWE-bench 74.9%達成

15. 料金体系の比較
    15.1. トークン計算の違い
        15.1.1. OpenAI: 入力・出力トークンで課金
        15.1.2. Anthropic: 同様に入力・出力トークンで課金、ただし料金体系が異なる
    
    15.2. 参考料金（2025年1月時点、1Mトークンあたり）
        15.2.1. GPT-5: 入力料金 $1.25、出力料金 $10 (2025年8月リリース、最新フラッグシップモデル 272k入力/128k出力)
        15.2.2. GPT-5-mini: 入力料金 $0.25、出力料金 $2 (GPT-5の小型版、高速・低コスト)
        15.2.3. GPT-5-nano: 入力料金 $0.05、出力料金 $0.40 (超軽量版、最速処理)
        15.2.4. GPT-4o: 入力料金 $2.50、出力料金 $10 (高性能モデル)
        15.2.5. GPT-4o-mini: 入力料金 $0.15、出力料金 $0.60 (コスト効率が良い小型モデル)
        15.2.6. GPT-3.5-Turbo: 入力料金 $0.50、出力料金 $1.50 (エコノミーオプション)
        15.2.7. Claude-4-Opus: 入力料金 $15、出力料金 $75 (最高性能モデル)
        15.2.8. Claude-3.5-Sonnet / Claude-4-Sonnet: 入力料金 $3、出力料金 $15 (バランス型高性能モデル)
        15.2.9. Claude-3-Haiku: 入力料金 $0.25、出力料金 $1.25 (コスト効率重視)
        
        15.2.10. 追加の料金オプション:
            - GPT-5 推論レベル: minimal/low/medium/highの4段階で処理時間とコストを調整可能
            - GPT-5 Pro (ChatGPT Pro $200/月): 無制限アクセス、拡張テスト時計算
            - Anthropic Prompt Caching: キャッシュ読み取りで最大90%のコスト削減
            - Anthropic Batch API: 非同期処理で50%割引（入力・出力両方）
            - OpenAI Web Search: GPT-5に標準搭載、GPT-4oでは検索コンテンツトークンは無料
        
        15.2.11. 注意: 料金は変動する可能性があるため、最新情報を以下で確認すること
            - OpenAI: https://openai.com/api/pricing/
            - Anthropic: https://www.anthropic.com/pricing

16. 移植時の注意事項
    16.1. レート制限
        16.1.1. OpenAI: TPM（Tokens Per Minute）、RPM（Requests Per Minute）
        16.1.2. Anthropic: 同様の制限あり、ただし具体的な値は異なる
        16.1.3. 移植時はレート制限の再調整が必要
    
    16.2. エラーハンドリング
        # OpenAI
        from openai import OpenAIError, RateLimitError
        
        # Anthropic
        from anthropic import AnthropicError, RateLimitError
        
        エラークラス名は類似しているが、インポート元が異なる
    
    16.3. 非同期処理
        # OpenAI
        from openai import AsyncOpenAI
        async_client = AsyncOpenAI()
        
        # Anthropic
        from anthropic import AsyncAnthropic
        async_client = AsyncAnthropic()
        
        両APIとも非同期クライアントをサポート

17. 移植チェックリスト
    17.1. Phase 1: 準備
        17.1.1. Anthropic APIキーの取得
        17.1.2. anthropic Pythonライブラリのインストール
        17.1.3. 既存のOpenAI API使用箇所の洗い出し
        17.1.4. テスト環境の構築
    
    17.2. Phase 2: 基本機能の移植
        17.2.1. クライアント初期化の変更
        17.2.2. 基本的なテキスト生成の移植
        17.2.3. システムプロンプトの移行
        17.2.4. エラーハンドリングの更新
    
    17.3. Phase 3: 高度な機能の移植
        17.3.1. 構造化出力の実装変更
        17.3.2. Function Calling → Tool Use への移行
        17.3.3. 画像処理の移植
        17.3.4. ストリーミング処理の更新
    
    17.4. Phase 4: 特殊機能の対応
        17.4.1. 音声処理の代替実装
        17.4.2. Embeddings機能の代替検討
        17.4.3. Fine-tuning依存部分の再設計
    
    17.5. Phase 5: 最適化とテスト
        17.5.1. レート制限の調整
        17.5.2. コスト最適化
        17.5.3. パフォーマンステスト
        17.5.4. 統合テスト

18. 不足情報と推奨事項
    18.1. 現時点で不足している情報
        18.1.1. Embeddings API
            - Anthropic APIにはEmbeddings生成機能がない
            - 代替案: OpenAI Embeddings APIの継続使用、または他のEmbeddingサービス
        
        18.1.2. Fine-tuning
            - Anthropic APIはFine-tuning未対応
            - 代替案: プロンプトエンジニアリング、Few-shot learning
        
        18.1.3. DALL-E相当の画像生成
            - Anthropic APIは画像生成機能なし
            - 代替案: DALL-E APIの継続使用、Stable Diffusion等
        
        18.1.4. Assistants API
            - Anthropic APIにAssistants API相当機能なし
            - 代替案: カスタム実装が必要
        
        18.1.5. Batch API
            - 大量処理用のBatch APIが未実装
            - 代替案: 独自のバッチ処理実装
    
    18.2. 移植前の確認事項
        18.2.1. コンプライアンス要件
            - データ保存ポリシーの違い
            - 地域制限の確認
        
        18.2.2. SLA（Service Level Agreement）
            - 可用性保証の違い
            - サポート体制の違い
        
        18.2.3. SDK機能の完全性
            - 使用している全機能のAnthropic API対応状況
            - サードパーティライブラリの互換性
    
    18.3. 推奨される移植アプローチ
        18.3.1. 段階的移植
            - 新規機能から順次Anthropic APIへ移行
            - 重要度の低い機能から試験的に移植
        
        18.3.2. ハイブリッド運用
            - 音声・画像生成はOpenAI API継続
            - テキスト処理をAnthropic APIへ移行
        
        18.3.3. 抽象化レイヤーの実装
            class LLMProvider:
                def __init__(self, provider="anthropic"):
                    if provider == "anthropic":
                        self.client = Anthropic()
                    elif provider == "openai":
                        self.client = OpenAI()
                
                def generate_text(self, prompt, **kwargs):
                    # 統一インターフェース実装
                    pass

19. サンプル移植コード
    19.1. 完全な移植例：会話型チャットボット
        19.1.1. OpenAI版
            from openai import OpenAI
            
            class OpenAIChatbot:
                def __init__(self):
                    self.client = OpenAI()
                    self.conversation = [
                        {"role": "system", "content": "You are a helpful assistant"}
                    ]
                
                def chat(self, user_input):
                    self.conversation.append({"role": "user", "content": user_input})
                    
                    response = self.client.chat.completions.create(
                        model="gpt-4",
                        messages=self.conversation,
                        temperature=0.7
                    )
                    
                    assistant_message = response.choices[0].message.content
                    self.conversation.append({"role": "assistant", "content": assistant_message})
                    
                    return assistant_message
        
        19.1.2. Anthropic版
            from anthropic import Anthropic
            
            class AnthropicChatbot:
                def __init__(self):
                    self.client = Anthropic()
                    self.system_prompt = "You are a helpful assistant"
                    self.conversation = []
                
                def chat(self, user_input):
                    self.conversation.append({"role": "user", "content": user_input})
                    
                    message = self.client.messages.create(
                        model="claude-3-5-sonnet-20241022",
                        max_tokens=1024,
                        temperature=0.7,
                        system=self.system_prompt,
                        messages=self.conversation
                    )
                    
                    assistant_message = message.content[0].text
                    self.conversation.append({"role": "assistant", "content": assistant_message})
                    
                    return assistant_message

20. まとめ
    20.1. OpenAI APIからAnthropic APIへの移植は、基本的な機能については比較的直接的な変換が可能ですが、以下の点に注意が必要です
    
    20.2. 移植が容易な機能
        20.2.1. テキスト生成
        20.2.2. 構造化出力（実装方法は異なる）
        20.2.3. 画像理解（GPT-5はマルチモーダル性能向上）
        20.2.4. ストリーミング
        20.2.5. Web検索（GPT-5に内蔵、Claudeは外部連携必要）
    
    20.3. 移植に工夫が必要な機能
        20.3.1. Function Calling → Tool Use
        20.3.2. システムメッセージの扱い
        20.3.3. レスポンス構造の処理
    
    20.4. 代替実装が必要な機能
        20.4.1. 音声処理（TTS/STT）
        20.4.2. 画像生成
        20.4.3. Embeddings
        20.4.4. Fine-tuning
    
    20.5. 移植を成功させるためには、段階的なアプローチと十分なテストが重要です。
          また、両APIの特性を理解し、それぞれの強みを活かしたハイブリッドアーキテクチャの検討も推奨されます。
