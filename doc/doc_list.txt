Memo
ーーーーーーーーーーーーーーーーーーーー


ーーーーーーーーーーーーーーーーーーーー
[テスト]
  - a00（通常版）のみ: make test-a00
  - a00（通常版）+ fixed 版まとめて: make test-a00-all
  - a00 のHTMLカバレッジ: make test-a00-html / make test-a00-all-html

ーーーーーーーーー
セットアップ

  - 仮想環境作成/有効化: python3 -m venv .venv && source .venv/bin/activate
  - 依存インストール: pip install -r requirements.txt
  - 追加テストツール（任意）: make install-test-deps

  基本実行

  - 全テスト: pytest -v または make test
  - 単体/統合のみ: make test-unit / make test-integration
  - 前回失敗のみ: make test-quick
  - 並列実行（xdist必要）: make test-parallel

  カバレッジ付き実行

  - 全体カバレッジ + HTML: pytest --cov=. --cov-report=term --cov-report=html または make test-cov
  - レポートを開く（macOS）: make coverage-report（ファイル: htmlcov/index.html）

  a00 専用ターゲット

  - a00（通常版）のみ: make test-a00
  - a00（通常版）+ fixed 版まとめて: make test-a00-all
  - a00 のHTMLカバレッジ: make test-a00-html / make test-a00-all-html

  マーカー指定（必要に応じて）

  - 例: 単体だけ: pytest -m unit -v
  - 複数指定例: pytest -m "integration and not slow" -v

  クリーンアップ

  - テスト成果物削除: make clean

  メモ

  - HTMLレポートは htmlcov/index.html に出力。閾値は .coveragerc の fail_under = 15 を参照。


ーーーーーーーーーーーーーーーーーーーーー
### doc/openai_api.md:
- OpenAI APIの全機能（テキスト生成、構造化出力、FunctionCalling、画像・音声処理、会話管理、推論パターン）を網羅したサンプルプログラムと実装例のカタログ。

### doc/anthropic_api.md:
- Anthropic Claude APIの全機能（メッセージ生成、Tool使用、画像解析、会話状態管理、推論パターン）を網羅したサンプルプログラムと実装例のカタログ。

### doc/openai_to_anthropic_migration_spec.md:
- OpenAI APIからAnthropic ClaudeAPIへの移植に必要な技術仕様、
  コード変換例、機能対応表、および移植時の注意事項を網羅した包括的な移行ガイド。


ーーーーーーーーーーーーーーーー
README.md を最新版に、かつ以下の資料を統合した資料にアップデートしたい。
  OpenAI APIの習得を主眼とし、
  全体構成、記述内容まで、全体的に見直し、作成せよ。

  （1）以下のREADME資料の構成、リンク、1行概要を持つ。
  　README_setup.md

・プログラムの構成

[OpenAI APIのみの速習版]
a0_simple_api.ipynb



[OpenAI API]
a00_responses_api.py
a01_structured_outputs_parse_schema.py
a02_responses_tools_pydantic_parse.py
a03_images_and_vision.py
a04_audio_speeches.py
a05_conversation_state.py
a06_reasoning_chain_of_thought.py

[utilities]
a10_get_vsid.py
get_cities_list.py

[ccommon]
helper_api.py
helper_st.py

------------------------
最高性能モデル

Claude Opus 4.1 (claude-opus-4-1-20250805)
Claude Opus 4 (claude-opus-4-20250514)
Claude Sonnet 4 (claude-sonnet-4-20250514)

# どの環境でも安定
python -m pip install -r requirements.txt

[サンプルプログラム]
a10_00_responses_api.py
a10_01_structured_outputs_parse_schema.py
a10_02_responses_tools_pydantic_parse.py
a10_03_images_and_vision.py
a10_04_audio_speeches.py
a10_05_conversation_state.py
a10_06_reasoning_chain_of_thought.py

[ヘルパー関数]
helper_api.py
helper_st.py

[その他]
a10_get_vsid.py
et_cities_list.py

a10_00_responses_api.py
    TextResponseDemo - 基本テキスト応答
    MemoryResponseDemo - 会話履歴付き応答
    ImageResponseDemo - 画像入力（URL・Base64対応）
    StructuredOutputDemo - 構造化出力（create・parse対応）
    WeatherDemo - OpenWeatherMap API連携
    ToolsDemo - FileSearch・WebSearch統合
    FileSearchStandaloneDemo - FileSearch専用
    WebSearchStandaloneDemo - WebSearch専用
    ComputerUseDemo - Computer Use Tool
    ConversationStateDemo - 会話状態管理

city.list.json.gz
https://bulk.openweathermap.org/sample/

###  ----------------------------------------------
⏺ 各モジュールからOpenAI APIの利用箇所を抽出しました。以下に列挙します：
  OpenAI API 利用箇所
###  ----------------------------------------------
  a10_00_responses_api.py（存在しない - a10_00_responses_api.pyか別名のファイルの可能性）

  a01_structured_outputs_parse_schema.py

  - Line 229: openai_client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
  - Line 230: return openai_client.responses.parse(**api_params)

  a02_responses_tools_pydantic_parse.py

  - Line 309: response = self.client.responses.parse(model=model, input=messages, tools=[...])
  - Line 421: response = self.client.responses.parse(model=model, input=messages, tools=[...])
  - Line 578: response = self.client.responses.parse(model=model, input=messages, tools=[...])
  - Line 716: response = self.client.responses.parse(model=model, input=messages, text_format=MathResponse)
  - Line 790: response = self.client.responses.parse(model=model, input=messages, text_format=PersonInfo)
  - Line 849: response = self.client.responses.parse(model=model, input=messages, text_format=ExtractedData)
  - Line 914: response = self.client.responses.parse(model=model, input=messages, text_format=Query)
  - Line 973: response = self.client.responses.parse(model=model, input=messages, text_format=TaskWithPriority)
  - Line 1035: response = self.client.responses.parse(model=model, input=messages, text_format=MathSolution)
  - Line 1108: response = self.client.responses.parse(model=model, input=messages, text_format=QAResponse)

  a03_images_and_vision.py

  - Line 236: response = self.client.responses.create(model=self.model, input=messages)
  - Line 396: response = self.client.responses.create(model=self.model, input=messages)
  - Line 480: response = self.client.images.generate(model=model, prompt=prompt, size=size, quality=quality, n=1)

  a04_audio_speeches.py

  - Line 357: return self.openai_client.audio.speech.with_streaming_response.create(...)
  - Line 365: return self.openai_client.audio.speech.create(...)
  - Line 438: return self.openai_client.audio.transcriptions.create(...)
  - Line 543: return self.openai_client.audio.translations.create(...)
  - Line 552: return self.openai_client.audio.transcriptions.create(...)
  - Line 585: resp = self.openai_client.chat.completions.create(...)
  - Line 824: return self.openai_client.audio.transcriptions.create(...)
  - Line 845: return self.openai_client.chat.completions.create(...)
  - Line 855: return self.openai_client.audio.speech.create(...)

  a05_conversation_state.py

  - Line 237: response = self.client.responses.create(model=self.model, input=messages)
  - Line 258: response = self.client.responses.create(model=self.model, input=query,
  previous_response_id=initial_response.id)
  - Line 356: response = self.client.responses.create(model=self.model, input=query, tools=[tool])
  - Line 382: structured_response = self.client.responses.parse(...)
  - Line 538: response = self.client.responses.create(model="gpt-4.1", input=query, tools=[weather_tool])

  a06_reasoning_chain_of_thought.py

  - Line 281: response = self.client.responses.create(model=self.model, input=messages)
  - Line 407: response = self.client.responses.create(model=self.model, input=messages)
  - Line 535: response = self.client.responses.create(model=self.model, input=messages)
  - Line 671: response = self.client.responses.create(model=self.model, input=messages)
  - Line 809: response = self.client.responses.create(model=self.model, input=messages)

  helper_api.py

  - Line 700: self.client = OpenAI(api_key=api_key)
  - Line 732: return self.client.responses.create(**params)
  - Line 769: return self.client.responses.parse(**params)
  - Line 784: return self.client.chat.completions.create(**params)

  helper_st.py

  - 該当行なし: このファイルはUI関連のヘルパー関数のみで、直接的なOpenAI API呼び出しはありません

  主要なAPIパターン

  1. responses.create: 一般的な応答生成
  2. responses.parse: 構造化出力（Pydanticモデル使用）
  3. audio.speech.create: テキスト→音声変換
  4. audio.transcriptions.create: 音声→テキスト変換
  5. audio.translations.create: 音声→英語テキスト変換
  6. images.generate: 画像生成（DALL-E）
  7. chat.completions.create: チャット完了API

###  ----------------------------------------------

###  ----------------------------------------------
### 設計書：作成用のプロンプト
### ----------------------------------------------
下記仕様で以下の設計書を更新せよ。
（コードは、設計書と同名.pyのプログラムである）
doc/a00_responses_api.md
doc/a01_structured_outputs_parse_schema.md
doc/a02_responses_tools_pydantic_parse.md
doc/a03_images_and_vision.md
doc/a04_audio_speeches.md
oc/a05_conversation_state.md
doc/a06_reasoning_chain_of_thought.md
doc/helper_api.md
doc/helper_st.md

基本構造は、そのままで、
不足情報があれば、指摘せよ。

仕様書：
仕様書、詳細設計書、各種、処理フローの作成

概要書
・処理の概要
・サブプログラムの一覧表：
　（下記が例だが、表で提供して欲しい：）
a10_00_responses_api.py
    TextResponseDemo - 基本テキスト応答
    MemoryResponseDemo - 会話履歴付き応答
    ImageResponseDemo - 画像入力（URL・Base64対応）
    StructuredOutputDemo - 構造化出力（create・parse対応）
    WeatherDemo - OpenWeatherMap API連携
    ToolsDemo - FileSearch・WebSearch統合
    FileSearchStandaloneDemo - FileSearch専用
    WebSearchStandaloneDemo - WebSearch専用
    ComputerUseDemo - Computer Use Tool
    ConversationStateDemo - 会話状態管理

・mainの処理の流れ

クラス、関数・一覧
・列データ：　関数名, 処理概要

関数の詳細設計書
・処理概要
・処理の流れ
・IPO(INPUT、PROCESS、OUTPUT)

----------------------------------

