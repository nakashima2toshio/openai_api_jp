# üìã a10_04_audio_speeches.py Ë®≠Ë®àÊõ∏

## üìù ÁõÆÊ¨°

1. [üìñ Ê¶ÇË¶ÅÊõ∏](#üìñ-Ê¶ÇË¶ÅÊõ∏)
2. [üîß „Ç∑„Çπ„ÉÜ„É†ÊßãÊàê](#üîß-„Ç∑„Çπ„ÉÜ„É†ÊßãÊàê)
3. [üìã Èñ¢Êï∞‰∏ÄË¶ß](#üìã-Èñ¢Êï∞‰∏ÄË¶ß)
4. [üìë Èñ¢Êï∞Ë©≥Á¥∞Ë®≠Ë®à](#üìë-Èñ¢Êï∞Ë©≥Á¥∞Ë®≠Ë®à)
5. [‚öôÔ∏è ÊäÄË°ì‰ªïÊßò](#‚öôÔ∏è-ÊäÄË°ì‰ªïÊßò)
6. [üö® „Ç®„É©„Éº„Éè„É≥„Éâ„É™„É≥„Ç∞](#üö®-„Ç®„É©„Éº„Éè„É≥„Éâ„É™„É≥„Ç∞)

---

## üìñ Ê¶ÇË¶ÅÊõ∏

### üéØ Âá¶ÁêÜ„ÅÆÊ¶ÇË¶Å

**OpenAI Audio & Speech API Áµ±ÂêàÂá¶ÁêÜ„Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥**

Êú¨„Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥„ÅØ„ÄÅOpenAI Audio API„ÅÆÂåÖÊã¨ÁöÑ„Å™Ê©üËÉΩ„ÇíÁµ±Âêà„Åó„ÅüStreamlit Web„Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥„Åß„Åô„ÄÇ„ÉÜ„Ç≠„Çπ„ÉàË™≠„Åø‰∏ä„ÅíÔºàTTSÔºâ„ÄÅÈü≥Â£∞„ÉÜ„Ç≠„Çπ„ÉàÂ§âÊèõÔºàSTTÔºâ„ÄÅÈü≥Â£∞ÁøªË®≥„ÄÅ„É™„Ç¢„É´„Çø„Ç§„É†API„ÄÅÈÄ£ÈéñÈü≥Â£∞„Ç®„Éº„Ç∏„Çß„É≥„Éà„Å™„Å©„ÄÅÈü≥Â£∞Âá¶ÁêÜ„ÅÆÂÖ®Ëà¨ÁöÑ„Å™„ÉØ„Éº„ÇØ„Éï„É≠„Éº„Çí‰ΩìÈ®ì„ÉªÂ≠¶Áøí„Åß„Åç„Åæ„Åô„ÄÇ

#### üåü ‰∏ªË¶ÅÊ©üËÉΩ

| Ê©üËÉΩ | Ë™¨Êòé |
|------|------|
| üé§ **Text to Speech** | „ÉÜ„Ç≠„Çπ„Éà„Çí„É™„Ç¢„É´„Çø„Ç§„É†„Çπ„Éà„É™„Éº„Éü„É≥„Ç∞Èü≥Â£∞Â§âÊèõ |
| üìù **Speech to Text** | Èü≥Â£∞„Éï„Ç°„Ç§„É´„ÅÆÈ´òÁ≤æÂ∫¶„ÉÜ„Ç≠„Çπ„ÉàÂ§âÊèõ |
| üåê **Speech Translation** | Èü≥Â£∞„ÅÆËã±Ë™ûÁøªË®≥„Éª„Éï„Ç©„Éº„É´„Éê„ÉÉ„ÇØÊ©üËÉΩ‰ªò„Åç |
| üîÑ **Realtime API** | WebSocketÂèåÊñπÂêë„É™„Ç¢„É´„Çø„Ç§„É†Èü≥Â£∞ÂØæË©± |
| ü§ñ **Chained Voice Agent** | Èü≥Â£∞‚Üí„ÉÜ„Ç≠„Çπ„Éà‚ÜíChat‚ÜíÈü≥Â£∞„ÅÆÈÄ£ÈéñÂá¶ÁêÜ |
| üìÅ **„Éï„Ç°„Ç§„É´ÁÆ°ÁêÜ** | Èü≥Â£∞„Éª„ÉÜ„Ç≠„Çπ„Éà„Éï„Ç°„Ç§„É´„ÅÆÁµ±ÂêàÁÆ°ÁêÜ |
| üí∞ **„Ç≥„Çπ„ÉàË®àÁÆó** | „É™„Ç¢„É´„Çø„Ç§„É†„Ç≥„Çπ„ÉàÊé®ÂÆö„Éª‰ΩøÁî®ÈáèËøΩË∑° |

#### üé® Âá¶ÁêÜÂØæË±°„Éá„Éº„Çø

```mermaid
graph LR
    A["Text Input"] --> B["TTS Processing"]
    C["Audio File"] --> D["STT Processing"] 
    D --> E["Text Output"]
    B --> F["Audio Output"]
    C --> G["Translation"]
    G --> H["English Text"]
    I["Realtime Audio"] --> J["Live Conversation"]
    K["Voice Chain"] --> L["Multi-step Processing"]
```

### üîÑ main„ÅÆÂá¶ÁêÜ„ÅÆÊµÅ„Çå

```mermaid
flowchart TD
    Start(["App Start"]) --> Config["Configuration Load"]
    Config --> Client["OpenAI Client Init"]
    Client --> UI["Demo Selection UI"]
    
    UI --> Demo{"Demo Type"}
    Demo -->|TTS| A["Text to Speech Demo"]
    Demo -->|STT| B["Speech to Text Demo"]
    Demo -->|Translation| C["Speech Translation Demo"]
    Demo -->|Realtime| D["Realtime API Demo"]
    Demo -->|Chain| E["Chained Voice Agent Demo"]
    
    A --> Process1["Audio Generation"]
    B --> Process2["Audio Transcription"]
    C --> Process3["Audio Translation"]
    D --> Process4["Live Conversation"]
    E --> Process5["Sequential Processing"]
    
    Process1 --> Display["Result Display"]
    Process2 --> Display
    Process3 --> Display  
    Process4 --> Display
    Process5 --> Display
    
    Display --> UI
```

---

## üîß „Ç∑„Çπ„ÉÜ„É†ÊßãÊàê

### üì¶ ‰∏ªË¶Å„Ç≥„É≥„Éù„Éº„Éç„É≥„Éà

```mermaid
classDiagram
    class BaseDemo {
        <<abstract>>
        +string demo_name
        +ConfigManager config
        +OpenAI client
        +run()
        +setup_sidebar()
        +error_handler_ui()
    }

    class DemoManager {
        +dict demos
        +run_application()
        +setup_sidebar()
    }

    class TextToSpeechDemo {
        +run()
        +process_text_to_speech()
        +handle_streaming()
    }

    class SpeechToTextDemo {
        +run()
        +process_speech_to_text()
        +validate_audio_file()
    }

    class SpeechTranslationDemo {
        +run()
        +process_translation()
        +fallback_translation()
    }

    class RealtimeApiDemo {
        +run()
        +setup_realtime_connection()
        +handle_audio_stream()
    }

    class ChainedVoiceAgentDemo {
        +run()
        +execute_voice_chain()
        +manage_processing_steps()
    }

    class AudioProcessor {
        +validate_audio_format()
        +encode_decode_audio()
        +manage_file_operations()
    }

    class RealtimeManager {
        +websocket_connection()
        +audio_streaming()
        +session_management()
    }

    BaseDemo <|-- TextToSpeechDemo
    BaseDemo <|-- SpeechToTextDemo
    BaseDemo <|-- SpeechTranslationDemo
    BaseDemo <|-- RealtimeApiDemo
    BaseDemo <|-- ChainedVoiceAgentDemo
    DemoManager --> BaseDemo
    TextToSpeechDemo --> AudioProcessor
    SpeechToTextDemo --> AudioProcessor
    RealtimeApiDemo --> RealtimeManager
```

### üìã „Éá„Éº„Çø„Éï„É≠„Éº

```mermaid
graph TD
    A["User Input"] --> B{"Input Type"}
    B -->|Text| C["TTS Processing"]
    B -->|Audio| D["STT/Translation Processing"]
    B -->|Realtime| E["Live Stream Processing"]
    B -->|Chain| F["Sequential Processing"]
    
    C --> G["Audio Generation"]
    D --> H["Text Extraction"]
    E --> I["Bidirectional Communication"]
    F --> J["Multi-step Output"]
    
    G --> K["File Storage"]
    H --> K
    I --> K
    J --> K
    
    K --> L["User Interface Display"]
```

---

## üìã Èñ¢Êï∞‰∏ÄË¶ß

### üèóÔ∏è „Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥Âà∂Âæ°Èñ¢Êï∞

| Èñ¢Êï∞Âêç | ÂàÜÈ°û | Âá¶ÁêÜÊ¶ÇË¶Å | ÈáçË¶ÅÂ∫¶ |
|--------|------|----------|---------|
| `main()` | üéØ Âà∂Âæ° | „Ç¢„Éó„É™„Ç±„Éº„Ç∑„Éß„É≥Ëµ∑Âãï„Éª„Éá„É¢ÁÆ°ÁêÜ | ‚≠ê‚≠ê‚≠ê |
| `DemoManager.run_application()` | üéØ Âà∂Âæ° | „Éá„É¢Áµ±ÂêàÁÆ°ÁêÜ„ÉªÂÆüË°åÂà∂Âæ° | ‚≠ê‚≠ê‚≠ê |
| `BaseDemo.__init__()` | üîß ÂàùÊúüÂåñ | Âü∫Â∫ï„ÇØ„É©„ÇπÂàùÊúüÂåñ„ÉªË®≠ÂÆöÁÆ°ÁêÜ | ‚≠ê‚≠ê‚≠ê |

### üé§ Èü≥Â£∞Âá¶ÁêÜ„Éá„É¢Èñ¢Êï∞

#### TextToSpeechDemo
| Èñ¢Êï∞Âêç | ÂàÜÈ°û | Âá¶ÁêÜÊ¶ÇË¶Å | ÈáçË¶ÅÂ∫¶ |
|--------|------|----------|---------|
| `TextToSpeechDemo.run()` | üéØ ÂÆüË°å | „ÉÜ„Ç≠„Çπ„ÉàÈü≥Â£∞Â§âÊèõ„Éá„É¢ÂÆüË°å | ‚≠ê‚≠ê‚≠ê |
| `process_text_to_speech()` | üîÑ Âá¶ÁêÜ | TTS APIÂëº„Å≥Âá∫„Åó„ÉªÈü≥Â£∞ÁîüÊàê | ‚≠ê‚≠ê‚≠ê |

#### SpeechToTextDemo
| Èñ¢Êï∞Âêç | ÂàÜÈ°û | Âá¶ÁêÜÊ¶ÇË¶Å | ÈáçË¶ÅÂ∫¶ |
|--------|------|----------|---------|
| `SpeechToTextDemo.run()` | üéØ ÂÆüË°å | Èü≥Â£∞„ÉÜ„Ç≠„Çπ„ÉàÂ§âÊèõ„Éá„É¢ÂÆüË°å | ‚≠ê‚≠ê‚≠ê |
| `process_speech_to_text()` | üîÑ Âá¶ÁêÜ | STT APIÂëº„Å≥Âá∫„Åó„ÉªËª¢ÂÜôÂá¶ÁêÜ | ‚≠ê‚≠ê‚≠ê |

#### SpeechTranslationDemo
| Èñ¢Êï∞Âêç | ÂàÜÈ°û | Âá¶ÁêÜÊ¶ÇË¶Å | ÈáçË¶ÅÂ∫¶ |
|--------|------|----------|---------|
| `SpeechTranslationDemo.run()` | üéØ ÂÆüË°å | Èü≥Â£∞ÁøªË®≥„Éá„É¢ÂÆüË°å | ‚≠ê‚≠ê‚≠ê |
| `process_translation()` | üîÑ Âá¶ÁêÜ | Èü≥Â£∞ÁøªË®≥„Éª„Éï„Ç©„Éº„É´„Éê„ÉÉ„ÇØÂá¶ÁêÜ | ‚≠ê‚≠ê‚≠ê |

#### RealtimeApiDemo
| Èñ¢Êï∞Âêç | ÂàÜÈ°û | Âá¶ÁêÜÊ¶ÇË¶Å | ÈáçË¶ÅÂ∫¶ |
|--------|------|----------|---------|
| `RealtimeApiDemo.run()` | üéØ ÂÆüË°å | „É™„Ç¢„É´„Çø„Ç§„É†API„Éá„É¢ÂÆüË°å | ‚≠ê‚≠ê‚≠ê |
| `setup_realtime_connection()` | üîÑ Êé•Á∂ö | WebSocketÊé•Á∂ö„Éª„Çª„ÉÉ„Ç∑„Éß„É≥ÁÆ°ÁêÜ | ‚≠ê‚≠ê‚≠ê |

#### ChainedVoiceAgentDemo
| Èñ¢Êï∞Âêç | ÂàÜÈ°û | Âá¶ÁêÜÊ¶ÇË¶Å | ÈáçË¶ÅÂ∫¶ |
|--------|------|----------|---------|
| `ChainedVoiceAgentDemo.run()` | üéØ ÂÆüË°å | ÈÄ£ÈéñÈü≥Â£∞„Ç®„Éº„Ç∏„Çß„É≥„Éà„Éá„É¢ | ‚≠ê‚≠ê‚≠ê |
| `execute_voice_chain()` | üîÑ Âá¶ÁêÜ | 3ÊÆµÈöéÈü≥Â£∞Âá¶ÁêÜ„ÅÆÈÄ£ÈéñÂÆüË°å | ‚≠ê‚≠ê‚≠ê |

---

## üìë Èñ¢Êï∞Ë©≥Á¥∞Ë®≠Ë®à

### üé§ TextToSpeechDemo.run()

#### üéØ Âá¶ÁêÜÊ¶ÇË¶Å
„ÉÜ„Ç≠„Çπ„ÉàÂÖ•Âäõ„Åã„Çâ„Çπ„Éà„É™„Éº„Éü„É≥„Ç∞ÂØæÂøú„ÅÆÈ´òÂìÅË≥™Èü≥Â£∞ÁîüÊàê

#### üìä Âá¶ÁêÜ„ÅÆÊµÅ„Çå
```mermaid
graph TD
    A["Demo Start"] --> B["Model Selection UI"]
    B --> C["Voice Selection"]
    C --> D["Text Input Options"]
    D --> E{"Input Method"}
    E -->|Direct| F["Text Area Input"]
    E -->|File| G["TXT File Upload"]
    F --> H["Streaming Option"]
    G --> H
    H --> I{"Generate Button?"}
    I -->|No| J["Wait for Input"]
    I -->|Yes| K["TTS API Call"]
    K --> L["Audio File Generation"]
    L --> M["Audio Player Display"]
    M --> N["Download Option"]
    N --> J
```

#### üìã IPOË®≠Ë®à

| È†ÖÁõÆ | ÂÜÖÂÆπ |
|------|------|
| **INPUT** | „ÉÜ„Ç≠„Çπ„ÉàÂÖ•ÂäõÔºàÁõ¥Êé•ÂÖ•Âäõ/TXT„Éï„Ç°„Ç§„É´Ôºâ„ÄÅÈü≥Â£∞„É¢„Éá„É´„ÄÅÈü≥Â£∞Á®ÆÈ°û„ÄÅ„Çπ„Éà„É™„Éº„Éü„É≥„Ç∞Ë®≠ÂÆö |
| **PROCESS** | „ÉÜ„Ç≠„Çπ„ÉàÊ§úË®º ‚Üí TTS APIÂëº„Å≥Âá∫„Åó ‚Üí „Çπ„Éà„É™„Éº„Éü„É≥„Ç∞Èü≥Â£∞ÁîüÊàê ‚Üí MP3„Éï„Ç°„Ç§„É´‰ΩúÊàê |
| **OUTPUT** | MP3Èü≥Â£∞„Éï„Ç°„Ç§„É´„ÄÅÈü≥Â£∞„Éó„É¨„Ç§„É§„Éº„ÄÅ„ÉÄ„Ç¶„É≥„É≠„Éº„Éâ„É™„É≥„ÇØ„ÄÅÂá¶ÁêÜÁµ±Ë®à |

#### üîç TTS APIÂëº„Å≥Âá∫„Åó„Éë„Çø„Éº„É≥
```python
# „Çπ„Éà„É™„Éº„Éü„É≥„Ç∞TTS
with client.audio.speech.with_streaming_response.create(
    model=model,
    voice=voice,
    input=text
) as response:
    response.stream_to_file(output_path)

# Ê®ôÊ∫ñTTS
response = client.audio.speech.create(
    model=model,
    voice=voice,
    input=text
)
```

---

### üìù SpeechToTextDemo.run()

#### üéØ Âá¶ÁêÜÊ¶ÇË¶Å
Èü≥Â£∞„Éï„Ç°„Ç§„É´„ÅÆÈ´òÁ≤æÂ∫¶„ÉÜ„Ç≠„Çπ„ÉàËª¢ÂÜô„Éª„É°„Çø„Éá„Éº„Çø‰ªò„ÅçÂá∫Âäõ

#### üìä Âá¶ÁêÜ„ÅÆÊµÅ„Çå
```mermaid
graph TD
    A["Demo Start"] --> B["STT Model Selection"]
    B --> C["Audio File Upload"]
    C --> D["File Format Validation"]
    D --> E{"Valid File?"}
    E -->|No| F["Error Display"]
    E -->|Yes| G["Audio Preview"]
    G --> H{"Transcribe Button?"}
    H -->|No| I["Wait for Input"]
    H -->|Yes| J["STT API Call"]
    J --> K["Text Extraction"]
    K --> L["Transcript Display"]
    L --> M["Copy/Download Options"]
    M --> I
    F --> I
```

#### üìã IPOË®≠Ë®à

| È†ÖÁõÆ | ÂÜÖÂÆπ |
|------|------|
| **INPUT** | Èü≥Â£∞„Éï„Ç°„Ç§„É´ÔºàMP3/WAV/M4A„ÄÅ‚â§25MBÔºâ„ÄÅSTT„É¢„Éá„É´ÈÅ∏Êäû |
| **PROCESS** | „Éï„Ç°„Ç§„É´Ê§úË®º ‚Üí Èü≥Â£∞„Éó„É¨„Éì„É•„Éº ‚Üí STT APIÂëº„Å≥Âá∫„Åó ‚Üí Ëª¢ÂÜôÂá¶ÁêÜ |
| **OUTPUT** | Ëª¢ÂÜô„ÉÜ„Ç≠„Çπ„Éà„ÄÅ„É°„Çø„Éá„Éº„Çø„ÄÅ„Ç≥„Éî„Éº„Éª„ÉÄ„Ç¶„É≥„É≠„Éº„ÉâÊ©üËÉΩ |

#### üîç STT APIÂëº„Å≥Âá∫„Åó„Éë„Çø„Éº„É≥
```python
with open(audio_file, "rb") as f:
    transcript = client.audio.transcriptions.create(
        model=model,
        file=f,
        response_format="text"
    )
```

---

### üåê SpeechTranslationDemo.run()

#### üéØ Âá¶ÁêÜÊ¶ÇË¶Å
Èü≥Â£∞„Éï„Ç°„Ç§„É´„ÅÆËã±Ë™ûÁøªË®≥„Éª„Éï„Ç©„Éº„É´„Éê„ÉÉ„ÇØÊ©üËÉΩ‰ªò„ÅçÂìÅË≥™‰øùË®º

#### üìä Âá¶ÁêÜ„ÅÆÊµÅ„Çå
```mermaid
graph TD
    A["Demo Start"] --> B["Translation Model Selection"]
    B --> C["Audio File Upload"]
    C --> D["Primary Translation API"]
    D --> E{"Translation Success?"}
    E -->|Yes| F["Quality Check"]
    E -->|No| G["Fallback Translation"]
    F --> H["Translation Display"]
    G --> I["Chat API Translation"]
    I --> H
    H --> J["Copy/Download Options"]
```

#### üìã IPOË®≠Ë®à

| È†ÖÁõÆ | ÂÜÖÂÆπ |
|------|------|
| **INPUT** | Èü≥Â£∞„Éï„Ç°„Ç§„É´„ÄÅÁøªË®≥„É¢„Éá„É´ÈÅ∏Êäû |
| **PROCESS** | ‰∏ªË¶ÅÁøªË®≥API ‚Üí ÂìÅË≥™Á¢∫Ë™ç ‚Üí „Éï„Ç©„Éº„É´„Éê„ÉÉ„ÇØÂá¶ÁêÜ ‚Üí ÁµêÊûúÁµ±Âêà |
| **OUTPUT** | Ëã±Ë™ûÁøªË®≥„ÉÜ„Ç≠„Çπ„Éà„ÄÅÁøªË®≥„É°„Çø„Éá„Éº„Çø„ÄÅÂìÅË≥™ÊÉÖÂ†± |

---

### üîÑ RealtimeApiDemo.run()

#### üéØ Âá¶ÁêÜÊ¶ÇË¶Å
WebSocketÂèåÊñπÂêë„É™„Ç¢„É´„Çø„Ç§„É†Èü≥Â£∞ÂØæË©±„Ç∑„Çπ„ÉÜ„É†

#### üìä Âá¶ÁêÜ„ÅÆÊµÅ„Çå
```mermaid
graph TD
    A["Demo Start"] --> B["Dependency Check"]
    B --> C{"pyaudio Available?"}
    C -->|No| D["Installation Guide"]
    C -->|Yes| E["Connection Setup"]
    E --> F["Voice/Format Selection"]
    F --> G["WebSocket Connection"]
    G --> H["Bidirectional Audio Stream"]
    H --> I["Live Conversation"]
    I --> J["Session Management"]
    J --> K["Connection Close"]
```

#### üìã IPOË®≠Ë®à

| È†ÖÁõÆ | ÂÜÖÂÆπ |
|------|------|
| **INPUT** | „É™„Ç¢„É´„Çø„Ç§„É†„Éû„Ç§„ÇØÈü≥Â£∞„ÄÅÈü≥Â£∞Ë®≠ÂÆö„ÄÅVADË®≠ÂÆö |
| **PROCESS** | WebSocketÊé•Á∂ö ‚Üí ÂèåÊñπÂêëÈü≥Â£∞„Çπ„Éà„É™„Éº„Éü„É≥„Ç∞ ‚Üí „É™„Ç¢„É´„Çø„Ç§„É†Âá¶ÁêÜ |
| **OUTPUT** | „É™„Ç¢„É´„Çø„Ç§„É†Èü≥Â£∞ÂøúÁ≠î„ÄÅ„É©„Ç§„Éñ‰ºöË©±„Çª„ÉÉ„Ç∑„Éß„É≥ |

#### üîç „É™„Ç¢„É´„Çø„Ç§„É†APIÊé•Á∂ö„Éë„Çø„Éº„É≥
```python
async with async_client.beta.realtime.connect(
    model="gpt-4o-realtime-preview"
) as conn:
    await conn.session.update(session={
        "voice": voice,
        "input_audio_format": "pcm16",
        "turn_detection": {"type": "server_vad"}
    })
```

---

### ü§ñ ChainedVoiceAgentDemo.run()

#### üéØ Âá¶ÁêÜÊ¶ÇË¶Å
Èü≥Â£∞‚Üí„ÉÜ„Ç≠„Çπ„Éà‚ÜíChat‚ÜíÈü≥Â£∞„ÅÆ3ÊÆµÈöéÈÄ£ÈéñÂá¶ÁêÜ„Ç®„Éº„Ç∏„Çß„É≥„Éà

#### üìä Âá¶ÁêÜ„ÅÆÊµÅ„Çå
```mermaid
graph TD
    A["Demo Start"] --> B["Model Selection"]
    B --> C["Audio File Upload"]
    C --> D["Step 1: STT Processing"]
    D --> E["User Speech Transcript"]
    E --> F["Step 2: Chat Completion"]
    F --> G["AI Response Generation"]
    G --> H["Step 3: TTS Processing"]
    H --> I["AI Response Audio"]
    I --> J["Complete Chain Display"]
```

#### üìã IPOË®≠Ë®à

| È†ÖÁõÆ | ÂÜÖÂÆπ |
|------|------|
| **INPUT** | Èü≥Â£∞„Éï„Ç°„Ç§„É´„ÄÅSTT/TTS„É¢„Éá„É´ÈÅ∏Êäû„ÄÅÈü≥Â£∞Á®ÆÈ°ûÈÅ∏Êäû |
| **PROCESS** | „Çπ„ÉÜ„ÉÉ„Éó1ÔºàSTTÔºâ‚Üí „Çπ„ÉÜ„ÉÉ„Éó2ÔºàChatÔºâ‚Üí „Çπ„ÉÜ„ÉÉ„Éó3ÔºàTTSÔºâ„ÅÆÈÄ£ÈéñÂÆüË°å |
| **OUTPUT** | „É¶„Éº„Ç∂„ÉºËª¢ÂÜô„ÄÅAI„ÉÜ„Ç≠„Çπ„ÉàÂøúÁ≠î„ÄÅAIÈü≥Â£∞ÂøúÁ≠î„ÄÅÂÖ®„Çπ„ÉÜ„ÉÉ„Éó„Éï„Ç°„Ç§„É´ |

---

## ‚öôÔ∏è ÊäÄË°ì‰ªïÊßò

### üì¶ ‰æùÂ≠ò„É©„Ç§„Éñ„É©„É™

| „É©„Ç§„Éñ„É©„É™ | „Éê„Éº„Ç∏„Éß„É≥ | Áî®ÈÄî | ÈáçË¶ÅÂ∫¶ |
|-----------|-----------|------|---------|
| `streamlit` | ÊúÄÊñ∞ | üé® Web UI„Éï„É¨„Éº„É†„ÉØ„Éº„ÇØ | ‚≠ê‚≠ê‚≠ê |
| `openai` | ÊúÄÊñ∞ | ü§ñ OpenAI API SDK (sync/async) | ‚≠ê‚≠ê‚≠ê |
| `pyaudio` | ÊúÄÊñ∞ | üé§ „É™„Ç¢„É´„Çø„Ç§„É†Èü≥Â£∞„Ç≠„É£„Éó„ÉÅ„É£ | ‚≠ê‚≠ê‚≠ê |
| `simpleaudio` | ÊúÄÊñ∞ | üîä Èü≥Â£∞ÂÜçÁîüÊ©üËÉΩ | ‚≠ê‚≠ê‚≠ê |
| `tiktoken` | ÊúÄÊñ∞ | üî¢ „Éà„Éº„ÇØ„É≥Ë®àÁÆó„ÉªÁÆ°ÁêÜ | ‚≠ê‚≠ê |
| `asyncio` | Ê®ôÊ∫ñ | üîÑ ÈùûÂêåÊúüÂá¶ÁêÜ | ‚≠ê‚≠ê‚≠ê |
| `base64` | Ê®ôÊ∫ñ | üî§ Èü≥Â£∞„Éá„Éº„Çø„Ç®„É≥„Ç≥„Éº„Éâ | ‚≠ê‚≠ê |

### üóÉÔ∏è Èü≥Â£∞API‰ªïÊßò

#### üìã ÂØæÂøú„É¢„Éá„É´

```yaml
TTS_Models:
  standard: ["tts-1", "gpt-4o-mini-tts"]
  hd: ["tts-1-hd"]
  voices: ["alloy", "nova", "echo", "onyx", "shimmer"]
  max_chars: 4096
  
STT_Models:
  whisper: ["whisper-1"]
  transcribe: ["gpt-4o-transcribe"]
  formats: ["mp3", "wav", "m4a"]
  max_size_mb: 25

Translation_Models:
  primary: ["whisper-1", "gpt-4o-transcribe"]
  fallback: ["gpt-4o-mini"]

Realtime_Models:
  supported: ["gpt-4o-realtime-preview"]
  audio_format: "pcm16"
  sample_rate: 16000
```

#### üí∞ „Ç≥„Çπ„ÉàË®àÁÆó

```yaml
Pricing:
  tts-1: "$0.015 / 1K chars"
  tts-1-hd: "$0.030 / 1K chars"
  whisper-1: "$0.006 / minute"
  gpt-4o-transcribe: "$0.010 / minute"
  realtime: "usage-based pricing"
```

### üîÑ APIÁµ±Âêà„Éë„Çø„Éº„É≥

#### üé§ TTS APIÁµ±Âêà„Éë„Çø„Éº„É≥

```python
# „Çπ„Éà„É™„Éº„Éü„É≥„Ç∞TTSÔºàÊé®Â•®Ôºâ
with client.audio.speech.with_streaming_response.create(
    model=model,
    voice=voice,
    input=text
) as response:
    response.stream_to_file(output_path)

# Ê®ôÊ∫ñTTS
response = client.audio.speech.create(
    model=model,
    voice=voice, 
    input=text
)
```

#### üìù STT APIÁµ±Âêà„Éë„Çø„Éº„É≥

```python
# Èü≥Â£∞Ëª¢ÂÜô
with open(audio_file, "rb") as f:
    transcript = client.audio.transcriptions.create(
        model=model,
        file=f,
        response_format="text"
    )

# Èü≥Â£∞ÁøªË®≥
with open(audio_file, "rb") as f:
    translation = client.audio.translations.create(
        model="whisper-1",
        file=f,
        response_format="text"
    )
```

### üíæ „Éï„Ç°„Ç§„É´ÁÆ°ÁêÜ

#### üóÇÔ∏è „Éï„Ç°„Ç§„É´„Ç∑„Çπ„ÉÜ„É†ÊßãÈÄ†

```yaml
File_Structure:
  DATA_DIR/                    # Ë®≠ÂÆöÂèØËÉΩ„Éá„Éº„Çø„Éá„Ç£„É¨„ÇØ„Éà„É™
    audio/                     # Èü≥Â£∞„Éï„Ç°„Ç§„É´
      - input_audio.mp3
      - generated_speech.mp3
    text/                      # „ÉÜ„Ç≠„Çπ„Éà„Éï„Ç°„Ç§„É´  
      - input_text.txt
      - transcript.txt
    temp/                      # ‰∏ÄÊôÇ„Éï„Ç°„Ç§„É´
      - session_audio.wav
```

#### ‚öôÔ∏è „Éï„Ç°„Ç§„É´Êìç‰ΩúÊ©üËÉΩ

```python
# „Çµ„Éù„Éº„ÉàÂΩ¢Âºè
AUDIO_FORMATS = [".mp3", ".wav", ".m4a"]
TEXT_FORMATS = [".txt"]

# „Éï„Ç°„Ç§„É´„Çµ„Ç§„Ç∫Âà∂Èôê
MAX_AUDIO_SIZE_MB = 25
MAX_TEXT_CHARS = 4096

# Ëá™Âãï„Éá„Ç£„É¨„ÇØ„Éà„É™‰ΩúÊàê
Path(DATA_DIR).mkdir(exist_ok=True)
```

---

## üö® „Ç®„É©„Éº„Éè„É≥„Éâ„É™„É≥„Ç∞

### üìÑ „Ç®„É©„ÉºÂàÜÈ°û

| „Ç®„É©„ÉºÁ®ÆÂà• | ÂéüÂõ† | ÂØæÂá¶Ê≥ï | ÂΩ±ÈüøÂ∫¶ |
|-----------|------|--------|---------|
| **Èü≥Â£∞„Éï„Ç°„Ç§„É´ÂΩ¢Âºè„Ç®„É©„Éº** | üö´ ÈùûÂØæÂøúÂΩ¢Âºè„ÉªÁ†¥Êêç„Éï„Ç°„Ç§„É´ | „Çµ„Éù„Éº„ÉàÂΩ¢ÂºèË™¨Êòé„Éª„Éï„Ç°„Ç§„É´Á¢∫Ë™ç | üî¥ È´ò |
| **„Éï„Ç°„Ç§„É´„Çµ„Ç§„Ç∫Ë∂ÖÈÅé** | üìÅ 25MBÂà∂ÈôêË∂ÖÈÅé | „Éï„Ç°„Ç§„É´ÂúßÁ∏Æ„ÉªÂàÜÂâ≤ÊèêÊ°à | üî¥ È´ò |
| **APIÂëº„Å≥Âá∫„ÅóÂ§±Êïó** | üåê ÈÄö‰ø°„ÉªÂà∂Èôê„ÉªË™çË®ºÂïèÈ°å | Ë™çË®ºÁ¢∫Ë™ç„ÉªÂà∂ÈôêË™¨Êòé„Éª„É™„Éà„É©„Ç§ | üî¥ È´ò |
| **pyaudio‰æùÂ≠òÈñ¢‰øÇ„Ç®„É©„Éº** | üì¶ „É©„Ç§„Éñ„É©„É™Êú™„Ç§„É≥„Çπ„Éà„Éº„É´ | „Ç§„É≥„Çπ„Éà„Éº„É´ÊâãÈ†Ü„Éª‰ª£ÊõøÊ°àÊèêÁ§∫ | üü° ‰∏≠ |
| **„É™„Ç¢„É´„Çø„Ç§„É†Êé•Á∂öÂ§±Êïó** | üîÑ WebSocket„Éª„Éç„ÉÉ„Éà„ÉØ„Éº„ÇØÂïèÈ°å | Êé•Á∂öÁ¢∫Ë™ç„ÉªË®≠ÂÆöË¶ãÁõ¥„Åó | üü° ‰∏≠ |
| **Èü≥Â£∞ÂÜçÁîü„Ç®„É©„Éº** | üîä „Ç™„Éº„Éá„Ç£„Ç™„Éá„Éê„Ç§„ÇπÂïèÈ°å | „Éá„Éê„Ç§„ÇπÁ¢∫Ë™ç„Éª‰ª£ÊõøÊñπÊ≥ï | üü† ‰Ωé |

### üõ†Ô∏è „Ç®„É©„ÉºÂá¶ÁêÜÊà¶Áï•

#### üîß ÊÆµÈöéÁöÑ„Ç®„É©„ÉºÂá¶ÁêÜ

```mermaid
graph TD
    A["API Call"] --> B{"Success?"}
    B -->|Yes| C["Response Validation"]
    B -->|No| D["Error Classification"]
    C --> E{"Valid Response?"}
    E -->|Yes| F["Process Result"]
    E -->|No| G["Format Error"]
    D --> H["Retry Logic"]
    G --> I["Error Display"]
    H --> J{"Retry Success?"}
    J -->|Yes| F
    J -->|No| I
    I --> K["Recovery Options"]
```

#### ‚úÖ „Ç®„É©„Éº„É°„ÉÉ„Çª„Éº„Ç∏‰æã

```python
# Èü≥Â£∞„Éï„Ç°„Ç§„É´„Ç®„É©„Éº
st.error("‚ùå Èü≥Â£∞„Éï„Ç°„Ç§„É´„ÅÆÂá¶ÁêÜ„Å´Â§±Êïó„Åó„Åæ„Åó„Åü")
st.info("üí° ÂØæÂøúÂΩ¢Âºè: MP3, WAV, M4AÔºàÊúÄÂ§ß25MBÔºâ")

# pyaudio‰æùÂ≠òÈñ¢‰øÇ„Ç®„É©„Éº
st.error("‚ùå pyaudio„É©„Ç§„Éñ„É©„É™„ÅåË¶ã„Å§„Åã„Çä„Åæ„Åõ„Çì")
st.code("pip install pyaudio")
st.warning("‚ö†Ô∏è „É™„Ç¢„É´„Çø„Ç§„É†APIÊ©üËÉΩ„ÅØÂà©Áî®„Åß„Åç„Åæ„Åõ„Çì")

# APIÂà∂Èôê„Ç®„É©„Éº
st.error("‚ùå APIÂà∂Èôê„Å´ÈÅî„Åó„Åæ„Åó„Åü")
st.info("üí° ÂØæÂá¶Ê≥ï: „Åó„Å∞„Çâ„ÅèÂæÖ„Å£„Å¶„Åã„ÇâÂÜçÂÆüË°å„Åó„Å¶„Åè„Å†„Åï„ÅÑ")
```

#### üîÑ „É™„Éà„É©„Ç§Ê©üÊßã

```python
# ÊåáÊï∞„Éê„ÉÉ„ÇØ„Ç™„Éï‰ªò„Åç„É™„Éà„É©„Ç§
@retry(
    retry_strategy=ExponentialBackoff(),
    max_attempts=3,
    exceptions=(APIError, ConnectionError)
)
def api_call_with_retry():
    return client.audio.speech.create(...)

# „Éï„Ç©„Éº„É´„Éê„ÉÉ„ÇØÂá¶ÁêÜ
try:
    # ‰∏ªË¶ÅAPIÂëº„Å≥Âá∫„Åó
    result = primary_api_call()
except Exception:
    # „Éï„Ç©„Éº„É´„Éê„ÉÉ„ÇØÂá¶ÁêÜ
    result = fallback_api_call()
```

### üéØ „Éá„Éê„ÉÉ„Ç∞Ê©üËÉΩ

```python
# „Éá„Éê„ÉÉ„Ç∞ÊÉÖÂ†±„Éë„Éç„É´  
with st.expander("üêõ „Éá„Éê„ÉÉ„Ç∞ÊÉÖÂ†±"):
    st.json({
        "model": selected_model,
        "voice": selected_voice,
        "file_size": file_size,
        "processing_time": processing_time,
        "api_response": api_response_dict
    })

# „Éë„Éï„Ç©„Éº„Éû„É≥„ÇπÁõ£Ë¶ñ
performance_metrics = {
    "processing_time": end_time - start_time,
    "file_size_mb": file_size / (1024 * 1024),
    "characters_processed": len(text),
    "estimated_cost": calculate_cost(model, usage)
}
```

---

## üéâ „Åæ„Å®„ÇÅ

„Åì„ÅÆË®≠Ë®àÊõ∏„ÅØ„ÄÅ**a10_04_audio_speeches.py** „ÅÆÂåÖÊã¨ÁöÑ„Å™ÊäÄË°ì‰ªïÊßò„Å®ÂÆüË£ÖË©≥Á¥∞„ÇíÁ∂≤ÁæÖ„Åó„ÅüÂÆåÂÖ®„Éâ„Ç≠„É•„É°„É≥„Éà„Åß„Åô„ÄÇ

### üåü Ë®≠Ë®à„ÅÆ„Éè„Ç§„É©„Ç§„Éà

- **üéµ ÂåÖÊã¨ÁöÑÈü≥Â£∞Âá¶ÁêÜ**: TTS„ÉªSTT„ÉªÁøªË®≥„Éª„É™„Ç¢„É´„Çø„Ç§„É†„Éª„ÉÅ„Çß„Éº„É≥„ÅÆÂÖ®Ê©üËÉΩÁµ±Âêà
- **üîÑ „Çπ„Éà„É™„Éº„Éü„É≥„Ç∞ÂØæÂøú**: È´òÂäπÁéá„É™„Ç¢„É´„Çø„Ç§„É†Èü≥Â£∞Âá¶ÁêÜ
- **üõ°Ô∏è Â†ÖÁâ¢ÊÄß**: ÂåÖÊã¨ÁöÑ„Ç®„É©„Éº„Éè„É≥„Éâ„É™„É≥„Ç∞„Å®„Éï„Ç©„Éº„É´„Éê„ÉÉ„ÇØÊ©üËÉΩ
- **üí∞ „Ç≥„Çπ„ÉàÈÄèÊòéÊÄß**: „É™„Ç¢„É´„Çø„Ç§„É†„Ç≥„Çπ„ÉàË®àÁÆó„Éª‰ΩøÁî®ÈáèËøΩË∑°
- **üé® Áõ¥ÊÑüÁöÑUI**: Streamlit„Å´„Çà„Çã‰Ωø„ÅÑ„ÇÑ„Åô„ÅÑ„Ç§„É≥„Çø„Éº„Éï„Çß„Éº„Çπ

### üîß „Ç¢„Éº„Ç≠„ÉÜ„ÇØ„ÉÅ„É£ÁâπÂæ¥

- **üì¶ „É¢„Ç∏„É•„Éº„É´Ë®≠Ë®à**: BaseDemoÁ∂ôÊâø„Å´„Çà„ÇãÁµ±‰∏Ä„Ç§„É≥„Çø„Éº„Éï„Çß„Éº„Çπ
- **üîÑ ÈùûÂêåÊúüÂá¶ÁêÜ**: „É™„Ç¢„É´„Çø„Ç§„É†API„Åß„ÅÆÈ´òÊÄßËÉΩWebSocketÈÄö‰ø°
- **üìÅ „Éï„Ç°„Ç§„É´Áµ±ÂêàÁÆ°ÁêÜ**: Èü≥Â£∞„Éª„ÉÜ„Ç≠„Çπ„Éà„Éï„Ç°„Ç§„É´„ÅÆÁµ±‰∏ÄÁöÑÁÆ°ÁêÜ„Ç∑„Çπ„ÉÜ„É†
- **‚öôÔ∏è Ë®≠ÂÆöÈßÜÂãï**: config.yml„Å´„Çà„ÇãÊüîËªü„Å™„É¢„Éá„É´„Éª„Éë„É©„É°„Éº„ÇøÁÆ°ÁêÜ
- **üéØ ÊÆµÈöéÁöÑË§áÈõëÂ∫¶**: Âü∫Êú¨Ê©üËÉΩ„Åã„ÇâÈ´òÂ∫¶„Å™„É™„Ç¢„É´„Çø„Ç§„É†Âá¶ÁêÜ„Åæ„ÅßÂØæÂøú