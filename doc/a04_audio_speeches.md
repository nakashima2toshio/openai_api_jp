# ğŸ“‹ a10_04_audio_speeches.py è¨­è¨ˆæ›¸

## ğŸ“ ç›®æ¬¡

1. [ğŸ“– æ¦‚è¦æ›¸](#ğŸ“–-æ¦‚è¦æ›¸)
2. [ğŸ”§ ã‚·ã‚¹ãƒ†ãƒ æ§‹æˆ](#ğŸ”§-ã‚·ã‚¹ãƒ†ãƒ æ§‹æˆ)
3. [ğŸ“‹ é–¢æ•°ä¸€è¦§](#ğŸ“‹-é–¢æ•°ä¸€è¦§)
4. [ğŸ“‘ é–¢æ•°è©³ç´°è¨­è¨ˆ](#ğŸ“‘-é–¢æ•°è©³ç´°è¨­è¨ˆ)
5. [âš™ï¸ æŠ€è¡“ä»•æ§˜](#âš™ï¸-æŠ€è¡“ä»•æ§˜)
6. [ğŸš¨ ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°](#ğŸš¨-ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°)

---

## ğŸ“– æ¦‚è¦æ›¸

### ğŸ¯ å‡¦ç†ã®æ¦‚è¦

**OpenAI Audio & Speech API çµ±åˆå‡¦ç†ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³**

æœ¬ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã¯ã€OpenAI Audio APIã®åŒ…æ‹¬çš„ãªæ©Ÿèƒ½ã‚’çµ±åˆã—ãŸStreamlit Webã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§ã™ã€‚ãƒ†ã‚­ã‚¹ãƒˆèª­ã¿ä¸Šã’ï¼ˆTTSï¼‰ã€éŸ³å£°ãƒ†ã‚­ã‚¹ãƒˆå¤‰æ›ï¼ˆSTTï¼‰ã€éŸ³å£°ç¿»è¨³ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ APIã€é€£é–éŸ³å£°ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãªã©ã€éŸ³å£°å‡¦ç†ã®å…¨èˆ¬çš„ãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’ä½“é¨“ãƒ»å­¦ç¿’ã§ãã¾ã™ã€‚

#### ğŸŒŸ ä¸»è¦æ©Ÿèƒ½

| æ©Ÿèƒ½ | èª¬æ˜ |
|------|------|
| ğŸ¤ **Text to Speech** | ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°éŸ³å£°å¤‰æ› |
| ğŸ“ **Speech to Text** | éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®é«˜ç²¾åº¦ãƒ†ã‚­ã‚¹ãƒˆå¤‰æ› |
| ğŸŒ **Speech Translation** | éŸ³å£°ã®è‹±èªç¿»è¨³ãƒ»ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿèƒ½ä»˜ã |
| ğŸ”„ **Realtime API** | WebSocketåŒæ–¹å‘ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°å¯¾è©± |
| ğŸ¤– **Chained Voice Agent** | éŸ³å£°â†’ãƒ†ã‚­ã‚¹ãƒˆâ†’Chatâ†’éŸ³å£°ã®é€£é–å‡¦ç† |
| ğŸ“ **ãƒ•ã‚¡ã‚¤ãƒ«ç®¡ç†** | éŸ³å£°ãƒ»ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®çµ±åˆç®¡ç† |
| ğŸ’° **ã‚³ã‚¹ãƒˆè¨ˆç®—** | ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚³ã‚¹ãƒˆæ¨å®šãƒ»ä½¿ç”¨é‡è¿½è·¡ |

#### ğŸ¨ å‡¦ç†å¯¾è±¡ãƒ‡ãƒ¼ã‚¿

```mermaid
graph LR
    A["Text Input"] --> B["TTS Processing"]
    C["Audio File"] --> D["STT Processing"] 
    D --> E["Text Output"]
    B --> F["Audio Output"]
    C --> G["Translation"]
    G --> H["English Text"]
    I["Realtime Audio"] --> J["Live Conversation"]
    K["Voice Chain"] --> L["Multi-step Processing"]
```

### ğŸ”„ mainã®å‡¦ç†ã®æµã‚Œ

```mermaid
flowchart TD
    Start(["App Start"]) --> Config["Configuration Load"]
    Config --> Client["OpenAI Client Init"]
    Client --> UI["Demo Selection UI"]
    
    UI --> Demo{"Demo Type"}
    Demo -->|TTS| A["Text to Speech Demo"]
    Demo -->|STT| B["Speech to Text Demo"]
    Demo -->|Translation| C["Speech Translation Demo"]
    Demo -->|Realtime| D["Realtime API Demo"]
    Demo -->|Chain| E["Chained Voice Agent Demo"]
    
    A --> Process1["Audio Generation"]
    B --> Process2["Audio Transcription"]
    C --> Process3["Audio Translation"]
    D --> Process4["Live Conversation"]
    E --> Process5["Sequential Processing"]
    
    Process1 --> Display["Result Display"]
    Process2 --> Display
    Process3 --> Display  
    Process4 --> Display
    Process5 --> Display
    
    Display --> UI
```

---

## ğŸ”§ ã‚·ã‚¹ãƒ†ãƒ æ§‹æˆ

### ğŸ“¦ ä¸»è¦ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ

```mermaid
classDiagram
    class BaseDemo {
        <<abstract>>
        +string demo_name
        +ConfigManager config
        +OpenAI client
        +run()
        +setup_sidebar()
        +error_handler_ui()
    }

    class DemoManager {
        +dict demos
        +run_application()
        +setup_sidebar()
    }

    class TextToSpeechDemo {
        +run()
        +process_text_to_speech()
        +handle_streaming()
    }

    class SpeechToTextDemo {
        +run()
        +process_speech_to_text()
        +validate_audio_file()
    }

    class SpeechTranslationDemo {
        +run()
        +process_translation()
        +fallback_translation()
    }

    class RealtimeApiDemo {
        +run()
        +setup_realtime_connection()
        +handle_audio_stream()
    }

    class ChainedVoiceAgentDemo {
        +run()
        +execute_voice_chain()
        +manage_processing_steps()
    }

    class AudioProcessor {
        +validate_audio_format()
        +encode_decode_audio()
        +manage_file_operations()
    }

    class RealtimeManager {
        +websocket_connection()
        +audio_streaming()
        +session_management()
    }

    BaseDemo <|-- TextToSpeechDemo
    BaseDemo <|-- SpeechToTextDemo
    BaseDemo <|-- SpeechTranslationDemo
    BaseDemo <|-- RealtimeApiDemo
    BaseDemo <|-- ChainedVoiceAgentDemo
    DemoManager --> BaseDemo
    TextToSpeechDemo --> AudioProcessor
    SpeechToTextDemo --> AudioProcessor
    RealtimeApiDemo --> RealtimeManager
```

### ğŸ“‹ ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼

```mermaid
graph TD
    A["User Input"] --> B{"Input Type"}
    B -->|Text| C["TTS Processing"]
    B -->|Audio| D["STT/Translation Processing"]
    B -->|Realtime| E["Live Stream Processing"]
    B -->|Chain| F["Sequential Processing"]
    
    C --> G["Audio Generation"]
    D --> H["Text Extraction"]
    E --> I["Bidirectional Communication"]
    F --> J["Multi-step Output"]
    
    G --> K["File Storage"]
    H --> K
    I --> K
    J --> K
    
    K --> L["User Interface Display"]
```

---

## ğŸ“‹ é–¢æ•°ä¸€è¦§

### ğŸ—ï¸ ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³åˆ¶å¾¡é–¢æ•°

| é–¢æ•°å | åˆ†é¡ | å‡¦ç†æ¦‚è¦ | é‡è¦åº¦ |
|--------|------|----------|---------|
| `main()` | ğŸ¯ åˆ¶å¾¡ | ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³èµ·å‹•ãƒ»ãƒ‡ãƒ¢ç®¡ç† | â­â­â­ |
| `DemoManager.run_application()` | ğŸ¯ åˆ¶å¾¡ | ãƒ‡ãƒ¢çµ±åˆç®¡ç†ãƒ»å®Ÿè¡Œåˆ¶å¾¡ | â­â­â­ |
| `BaseDemo.__init__()` | ğŸ”§ åˆæœŸåŒ– | åŸºåº•ã‚¯ãƒ©ã‚¹åˆæœŸåŒ–ãƒ»è¨­å®šç®¡ç† | â­â­â­ |

### ğŸ¤ éŸ³å£°å‡¦ç†ãƒ‡ãƒ¢é–¢æ•°

#### TextToSpeechDemo
| é–¢æ•°å | åˆ†é¡ | å‡¦ç†æ¦‚è¦ | é‡è¦åº¦ |
|--------|------|----------|---------|
| `TextToSpeechDemo.run()` | ğŸ¯ å®Ÿè¡Œ | ãƒ†ã‚­ã‚¹ãƒˆéŸ³å£°å¤‰æ›ãƒ‡ãƒ¢å®Ÿè¡Œ | â­â­â­ |
| `process_text_to_speech()` | ğŸ”„ å‡¦ç† | TTS APIå‘¼ã³å‡ºã—ãƒ»éŸ³å£°ç”Ÿæˆ | â­â­â­ |

#### SpeechToTextDemo
| é–¢æ•°å | åˆ†é¡ | å‡¦ç†æ¦‚è¦ | é‡è¦åº¦ |
|--------|------|----------|---------|
| `SpeechToTextDemo.run()` | ğŸ¯ å®Ÿè¡Œ | éŸ³å£°ãƒ†ã‚­ã‚¹ãƒˆå¤‰æ›ãƒ‡ãƒ¢å®Ÿè¡Œ | â­â­â­ |
| `process_speech_to_text()` | ğŸ”„ å‡¦ç† | STT APIå‘¼ã³å‡ºã—ãƒ»è»¢å†™å‡¦ç† | â­â­â­ |

#### SpeechTranslationDemo
| é–¢æ•°å | åˆ†é¡ | å‡¦ç†æ¦‚è¦ | é‡è¦åº¦ |
|--------|------|----------|---------|
| `SpeechTranslationDemo.run()` | ğŸ¯ å®Ÿè¡Œ | éŸ³å£°ç¿»è¨³ãƒ‡ãƒ¢å®Ÿè¡Œ | â­â­â­ |
| `process_translation()` | ğŸ”„ å‡¦ç† | éŸ³å£°ç¿»è¨³ãƒ»ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç† | â­â­â­ |

#### RealtimeApiDemo
| é–¢æ•°å | åˆ†é¡ | å‡¦ç†æ¦‚è¦ | é‡è¦åº¦ |
|--------|------|----------|---------|
| `RealtimeApiDemo.run()` | ğŸ¯ å®Ÿè¡Œ | ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ APIãƒ‡ãƒ¢å®Ÿè¡Œ | â­â­â­ |
| `setup_realtime_connection()` | ğŸ”„ æ¥ç¶š | WebSocketæ¥ç¶šãƒ»ã‚»ãƒƒã‚·ãƒ§ãƒ³ç®¡ç† | â­â­â­ |

#### ChainedVoiceAgentDemo
| é–¢æ•°å | åˆ†é¡ | å‡¦ç†æ¦‚è¦ | é‡è¦åº¦ |
|--------|------|----------|---------|
| `ChainedVoiceAgentDemo.run()` | ğŸ¯ å®Ÿè¡Œ | é€£é–éŸ³å£°ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆãƒ‡ãƒ¢ | â­â­â­ |
| `execute_voice_chain()` | ğŸ”„ å‡¦ç† | 3æ®µéšéŸ³å£°å‡¦ç†ã®é€£é–å®Ÿè¡Œ | â­â­â­ |

---

## ğŸ“‘ é–¢æ•°è©³ç´°è¨­è¨ˆ

### ğŸ¤ TextToSpeechDemo.run()

#### ğŸ¯ å‡¦ç†æ¦‚è¦
ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›ã‹ã‚‰ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¯¾å¿œã®é«˜å“è³ªéŸ³å£°ç”Ÿæˆ

#### ğŸ“Š å‡¦ç†ã®æµã‚Œ
```mermaid
graph TD
    A["Demo Start"] --> B["Model Selection UI"]
    B --> C["Voice Selection"]
    C --> D["Text Input Options"]
    D --> E{"Input Method"}
    E -->|Direct| F["Text Area Input"]
    E -->|File| G["TXT File Upload"]
    F --> H["Streaming Option"]
    G --> H
    H --> I{"Generate Button?"}
    I -->|No| J["Wait for Input"]
    I -->|Yes| K["TTS API Call"]
    K --> L["Audio File Generation"]
    L --> M["Audio Player Display"]
    M --> N["Download Option"]
    N --> J
```

#### ğŸ“‹ IPOè¨­è¨ˆ

| é …ç›® | å†…å®¹ |
|------|------|
| **INPUT** | ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›ï¼ˆç›´æ¥å…¥åŠ›/TXTãƒ•ã‚¡ã‚¤ãƒ«ï¼‰ã€éŸ³å£°ãƒ¢ãƒ‡ãƒ«ã€éŸ³å£°ç¨®é¡ã€ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°è¨­å®š |
| **PROCESS** | ãƒ†ã‚­ã‚¹ãƒˆæ¤œè¨¼ â†’ TTS APIå‘¼ã³å‡ºã— â†’ ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°éŸ³å£°ç”Ÿæˆ â†’ MP3ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ |
| **OUTPUT** | MP3éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã€éŸ³å£°ãƒ—ãƒ¬ã‚¤ãƒ¤ãƒ¼ã€ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒªãƒ³ã‚¯ã€å‡¦ç†çµ±è¨ˆ |

#### ğŸ” TTS APIå‘¼ã³å‡ºã—ãƒ‘ã‚¿ãƒ¼ãƒ³
```python
# ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°TTS
with client.audio.speech.with_streaming_response.create(
    model=model,
    voice=voice,
    input=text
) as response:
    response.stream_to_file(output_path)

# æ¨™æº–TTS
response = client.audio.speech.create(
    model=model,
    voice=voice,
    input=text
)
```

---

### ğŸ“ SpeechToTextDemo.run()

#### ğŸ¯ å‡¦ç†æ¦‚è¦
éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®é«˜ç²¾åº¦ãƒ†ã‚­ã‚¹ãƒˆè»¢å†™ãƒ»ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä»˜ãå‡ºåŠ›

#### ğŸ“Š å‡¦ç†ã®æµã‚Œ
```mermaid
graph TD
    A["Demo Start"] --> B["STT Model Selection"]
    B --> C["Audio File Upload"]
    C --> D["File Format Validation"]
    D --> E{"Valid File?"}
    E -->|No| F["Error Display"]
    E -->|Yes| G["Audio Preview"]
    G --> H{"Transcribe Button?"}
    H -->|No| I["Wait for Input"]
    H -->|Yes| J["STT API Call"]
    J --> K["Text Extraction"]
    K --> L["Transcript Display"]
    L --> M["Copy/Download Options"]
    M --> I
    F --> I
```

#### ğŸ“‹ IPOè¨­è¨ˆ

| é …ç›® | å†…å®¹ |
|------|------|
| **INPUT** | éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆMP3/WAV/M4Aã€â‰¤25MBï¼‰ã€STTãƒ¢ãƒ‡ãƒ«é¸æŠ |
| **PROCESS** | ãƒ•ã‚¡ã‚¤ãƒ«æ¤œè¨¼ â†’ éŸ³å£°ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ â†’ STT APIå‘¼ã³å‡ºã— â†’ è»¢å†™å‡¦ç† |
| **OUTPUT** | è»¢å†™ãƒ†ã‚­ã‚¹ãƒˆã€ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã€ã‚³ãƒ”ãƒ¼ãƒ»ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰æ©Ÿèƒ½ |

#### ğŸ” STT APIå‘¼ã³å‡ºã—ãƒ‘ã‚¿ãƒ¼ãƒ³
```python
with open(audio_file, "rb") as f:
    transcript = client.audio.transcriptions.create(
        model=model,
        file=f,
        response_format="text"
    )
```

---

### ğŸŒ SpeechTranslationDemo.run()

#### ğŸ¯ å‡¦ç†æ¦‚è¦
éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®è‹±èªç¿»è¨³ãƒ»ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿèƒ½ä»˜ãå“è³ªä¿è¨¼

#### ğŸ“Š å‡¦ç†ã®æµã‚Œ
```mermaid
graph TD
    A["Demo Start"] --> B["Translation Model Selection"]
    B --> C["Audio File Upload"]
    C --> D["Primary Translation API"]
    D --> E{"Translation Success?"}
    E -->|Yes| F["Quality Check"]
    E -->|No| G["Fallback Translation"]
    F --> H["Translation Display"]
    G --> I["Chat API Translation"]
    I --> H
    H --> J["Copy/Download Options"]
```

#### ğŸ“‹ IPOè¨­è¨ˆ

| é …ç›® | å†…å®¹ |
|------|------|
| **INPUT** | éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã€ç¿»è¨³ãƒ¢ãƒ‡ãƒ«é¸æŠ |
| **PROCESS** | ä¸»è¦ç¿»è¨³API â†’ å“è³ªç¢ºèª â†’ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç† â†’ çµæœçµ±åˆ |
| **OUTPUT** | è‹±èªç¿»è¨³ãƒ†ã‚­ã‚¹ãƒˆã€ç¿»è¨³ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã€å“è³ªæƒ…å ± |

---

### ğŸ”„ RealtimeApiDemo.run()

#### ğŸ¯ å‡¦ç†æ¦‚è¦
WebSocketåŒæ–¹å‘ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°å¯¾è©±ã‚·ã‚¹ãƒ†ãƒ 

#### ğŸ“Š å‡¦ç†ã®æµã‚Œ
```mermaid
graph TD
    A["Demo Start"] --> B["Dependency Check"]
    B --> C{"pyaudio Available?"}
    C -->|No| D["Installation Guide"]
    C -->|Yes| E["Connection Setup"]
    E --> F["Voice/Format Selection"]
    F --> G["WebSocket Connection"]
    G --> H["Bidirectional Audio Stream"]
    H --> I["Live Conversation"]
    I --> J["Session Management"]
    J --> K["Connection Close"]
```

#### ğŸ“‹ IPOè¨­è¨ˆ

| é …ç›® | å†…å®¹ |
|------|------|
| **INPUT** | ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒã‚¤ã‚¯éŸ³å£°ã€éŸ³å£°è¨­å®šã€VADè¨­å®š |
| **PROCESS** | WebSocketæ¥ç¶š â†’ åŒæ–¹å‘éŸ³å£°ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚° â†’ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‡¦ç† |
| **OUTPUT** | ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°å¿œç­”ã€ãƒ©ã‚¤ãƒ–ä¼šè©±ã‚»ãƒƒã‚·ãƒ§ãƒ³ |

#### ğŸ” ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ APIæ¥ç¶šãƒ‘ã‚¿ãƒ¼ãƒ³
```python
async with async_client.beta.realtime.connect(
    model="gpt-4o-realtime-preview"
) as conn:
    await conn.session.update(session={
        "voice": voice,
        "input_audio_format": "pcm16",
        "turn_detection": {"type": "server_vad"}
    })
```

---

### ğŸ¤– ChainedVoiceAgentDemo.run()

#### ğŸ¯ å‡¦ç†æ¦‚è¦
éŸ³å£°â†’ãƒ†ã‚­ã‚¹ãƒˆâ†’Chatâ†’éŸ³å£°ã®3æ®µéšé€£é–å‡¦ç†ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ

#### ğŸ“Š å‡¦ç†ã®æµã‚Œ
```mermaid
graph TD
    A["Demo Start"] --> B["Model Selection"]
    B --> C["Audio File Upload"]
    C --> D["Step 1: STT Processing"]
    D --> E["User Speech Transcript"]
    E --> F["Step 2: Chat Completion"]
    F --> G["AI Response Generation"]
    G --> H["Step 3: TTS Processing"]
    H --> I["AI Response Audio"]
    I --> J["Complete Chain Display"]
```

#### ğŸ“‹ IPOè¨­è¨ˆ

| é …ç›® | å†…å®¹ |
|------|------|
| **INPUT** | éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã€STT/TTSãƒ¢ãƒ‡ãƒ«é¸æŠã€éŸ³å£°ç¨®é¡é¸æŠ |
| **PROCESS** | ã‚¹ãƒ†ãƒƒãƒ—1ï¼ˆSTTï¼‰â†’ ã‚¹ãƒ†ãƒƒãƒ—2ï¼ˆChatï¼‰â†’ ã‚¹ãƒ†ãƒƒãƒ—3ï¼ˆTTSï¼‰ã®é€£é–å®Ÿè¡Œ |
| **OUTPUT** | ãƒ¦ãƒ¼ã‚¶ãƒ¼è»¢å†™ã€AIãƒ†ã‚­ã‚¹ãƒˆå¿œç­”ã€AIéŸ³å£°å¿œç­”ã€å…¨ã‚¹ãƒ†ãƒƒãƒ—ãƒ•ã‚¡ã‚¤ãƒ« |

---

## âš™ï¸ æŠ€è¡“ä»•æ§˜

### ğŸ“¦ ä¾å­˜ãƒ©ã‚¤ãƒ–ãƒ©ãƒª

| ãƒ©ã‚¤ãƒ–ãƒ©ãƒª | ãƒãƒ¼ã‚¸ãƒ§ãƒ³ | ç”¨é€” | é‡è¦åº¦ |
|-----------|-----------|------|---------|
| `streamlit` | æœ€æ–° | ğŸ¨ Web UIãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ | â­â­â­ |
| `openai` | æœ€æ–° | ğŸ¤– OpenAI API SDK (sync/async) | â­â­â­ |
| `pyaudio` | æœ€æ–° | ğŸ¤ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°ã‚­ãƒ£ãƒ—ãƒãƒ£ | â­â­â­ |
| `simpleaudio` | æœ€æ–° | ğŸ”Š éŸ³å£°å†ç”Ÿæ©Ÿèƒ½ | â­â­â­ |
| `tiktoken` | æœ€æ–° | ğŸ”¢ ãƒˆãƒ¼ã‚¯ãƒ³è¨ˆç®—ãƒ»ç®¡ç† | â­â­ |
| `asyncio` | æ¨™æº– | ğŸ”„ éåŒæœŸå‡¦ç† | â­â­â­ |
| `base64` | æ¨™æº– | ğŸ”¤ éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ | â­â­ |

### ğŸ—ƒï¸ éŸ³å£°APIä»•æ§˜

#### ğŸ“‹ å¯¾å¿œãƒ¢ãƒ‡ãƒ«

```yaml
TTS_Models:
  standard: ["tts-1", "gpt-4o-mini-tts"]
  hd: ["tts-1-hd"]
  voices: ["alloy", "nova", "echo", "onyx", "shimmer"]
  max_chars: 4096
  
STT_Models:
  whisper: ["whisper-1"]
  transcribe: ["gpt-4o-transcribe"]
  formats: ["mp3", "wav", "m4a"]
  max_size_mb: 25

Translation_Models:
  primary: ["whisper-1", "gpt-4o-transcribe"]
  fallback: ["gpt-4o-mini"]

Realtime_Models:
  supported: ["gpt-4o-realtime-preview"]
  audio_format: "pcm16"
  sample_rate: 16000
```

#### ğŸ’° ã‚³ã‚¹ãƒˆè¨ˆç®—

```yaml
Pricing:
  tts-1: "$0.015 / 1K chars"
  tts-1-hd: "$0.030 / 1K chars"
  whisper-1: "$0.006 / minute"
  gpt-4o-transcribe: "$0.010 / minute"
  realtime: "usage-based pricing"
```

### ğŸ”„ APIçµ±åˆãƒ‘ã‚¿ãƒ¼ãƒ³

#### ğŸ¤ TTS APIçµ±åˆãƒ‘ã‚¿ãƒ¼ãƒ³

```python
# ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°TTSï¼ˆæ¨å¥¨ï¼‰
with client.audio.speech.with_streaming_response.create(
    model=model,
    voice=voice,
    input=text
) as response:
    response.stream_to_file(output_path)

# æ¨™æº–TTS
response = client.audio.speech.create(
    model=model,
    voice=voice, 
    input=text
)
```

#### ğŸ“ STT APIçµ±åˆãƒ‘ã‚¿ãƒ¼ãƒ³

```python
# éŸ³å£°è»¢å†™
with open(audio_file, "rb") as f:
    transcript = client.audio.transcriptions.create(
        model=model,
        file=f,
        response_format="text"
    )

# éŸ³å£°ç¿»è¨³
with open(audio_file, "rb") as f:
    translation = client.audio.translations.create(
        model="whisper-1",
        file=f,
        response_format="text"
    )
```

### ğŸ’¾ ãƒ•ã‚¡ã‚¤ãƒ«ç®¡ç†

#### ğŸ—‚ï¸ ãƒ•ã‚¡ã‚¤ãƒ«ã‚·ã‚¹ãƒ†ãƒ æ§‹é€ 

```yaml
File_Structure:
  DATA_DIR/                    # è¨­å®šå¯èƒ½ãƒ‡ãƒ¼ã‚¿ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
    audio/                     # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«
      - input_audio.mp3
      - generated_speech.mp3
    text/                      # ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«  
      - input_text.txt
      - transcript.txt
    temp/                      # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«
      - session_audio.wav
```

#### âš™ï¸ ãƒ•ã‚¡ã‚¤ãƒ«æ“ä½œæ©Ÿèƒ½

```python
# ã‚µãƒãƒ¼ãƒˆå½¢å¼
AUDIO_FORMATS = [".mp3", ".wav", ".m4a"]
TEXT_FORMATS = [".txt"]

# ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºåˆ¶é™
MAX_AUDIO_SIZE_MB = 25
MAX_TEXT_CHARS = 4096

# è‡ªå‹•ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
Path(DATA_DIR).mkdir(exist_ok=True)
```

---

## ğŸš¨ ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°

### ğŸ“„ ã‚¨ãƒ©ãƒ¼åˆ†é¡

| ã‚¨ãƒ©ãƒ¼ç¨®åˆ¥ | åŸå›  | å¯¾å‡¦æ³• | å½±éŸ¿åº¦ |
|-----------|------|--------|---------|
| **éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã‚¨ãƒ©ãƒ¼** | ğŸš« éå¯¾å¿œå½¢å¼ãƒ»ç ´æãƒ•ã‚¡ã‚¤ãƒ« | ã‚µãƒãƒ¼ãƒˆå½¢å¼èª¬æ˜ãƒ»ãƒ•ã‚¡ã‚¤ãƒ«ç¢ºèª | ğŸ”´ é«˜ |
| **ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºè¶…é** | ğŸ“ 25MBåˆ¶é™è¶…é | ãƒ•ã‚¡ã‚¤ãƒ«åœ§ç¸®ãƒ»åˆ†å‰²ææ¡ˆ | ğŸ”´ é«˜ |
| **APIå‘¼ã³å‡ºã—å¤±æ•—** | ğŸŒ é€šä¿¡ãƒ»åˆ¶é™ãƒ»èªè¨¼å•é¡Œ | èªè¨¼ç¢ºèªãƒ»åˆ¶é™èª¬æ˜ãƒ»ãƒªãƒˆãƒ©ã‚¤ | ğŸ”´ é«˜ |
| **pyaudioä¾å­˜é–¢ä¿‚ã‚¨ãƒ©ãƒ¼** | ğŸ“¦ ãƒ©ã‚¤ãƒ–ãƒ©ãƒªæœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ« | ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ‰‹é †ãƒ»ä»£æ›¿æ¡ˆæç¤º | ğŸŸ¡ ä¸­ |
| **ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¥ç¶šå¤±æ•—** | ğŸ”„ WebSocketãƒ»ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å•é¡Œ | æ¥ç¶šç¢ºèªãƒ»è¨­å®šè¦‹ç›´ã— | ğŸŸ¡ ä¸­ |
| **éŸ³å£°å†ç”Ÿã‚¨ãƒ©ãƒ¼** | ğŸ”Š ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªãƒ‡ãƒã‚¤ã‚¹å•é¡Œ | ãƒ‡ãƒã‚¤ã‚¹ç¢ºèªãƒ»ä»£æ›¿æ–¹æ³• | ğŸŸ  ä½ |

### ğŸ› ï¸ ã‚¨ãƒ©ãƒ¼å‡¦ç†æˆ¦ç•¥

#### ğŸ”§ æ®µéšçš„ã‚¨ãƒ©ãƒ¼å‡¦ç†

```mermaid
graph TD
    A["API Call"] --> B{"Success?"}
    B -->|Yes| C["Response Validation"]
    B -->|No| D["Error Classification"]
    C --> E{"Valid Response?"}
    E -->|Yes| F["Process Result"]
    E -->|No| G["Format Error"]
    D --> H["Retry Logic"]
    G --> I["Error Display"]
    H --> J{"Retry Success?"}
    J -->|Yes| F
    J -->|No| I
    I --> K["Recovery Options"]
```

#### âœ… ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ä¾‹

```python
# éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚¨ãƒ©ãƒ¼
st.error("âŒ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†ã«å¤±æ•—ã—ã¾ã—ãŸ")
st.info("ğŸ’¡ å¯¾å¿œå½¢å¼: MP3, WAV, M4Aï¼ˆæœ€å¤§25MBï¼‰")

# pyaudioä¾å­˜é–¢ä¿‚ã‚¨ãƒ©ãƒ¼
st.error("âŒ pyaudioãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
st.code("pip install pyaudio")
st.warning("âš ï¸ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ APIæ©Ÿèƒ½ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“")

# APIåˆ¶é™ã‚¨ãƒ©ãƒ¼
st.error("âŒ APIåˆ¶é™ã«é”ã—ã¾ã—ãŸ")
st.info("ğŸ’¡ å¯¾å‡¦æ³•: ã—ã°ã‚‰ãå¾…ã£ã¦ã‹ã‚‰å†å®Ÿè¡Œã—ã¦ãã ã•ã„")
```

#### ğŸ”„ ãƒªãƒˆãƒ©ã‚¤æ©Ÿæ§‹

```python
# æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•ä»˜ããƒªãƒˆãƒ©ã‚¤
@retry(
    retry_strategy=ExponentialBackoff(),
    max_attempts=3,
    exceptions=(APIError, ConnectionError)
)
def api_call_with_retry():
    return client.audio.speech.create(...)

# ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†
try:
    # ä¸»è¦APIå‘¼ã³å‡ºã—
    result = primary_api_call()
except Exception:
    # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å‡¦ç†
    result = fallback_api_call()
```

### ğŸ¯ ãƒ‡ãƒãƒƒã‚°æ©Ÿèƒ½

```python
# ãƒ‡ãƒãƒƒã‚°æƒ…å ±ãƒ‘ãƒãƒ«  
with st.expander("ğŸ› ãƒ‡ãƒãƒƒã‚°æƒ…å ±"):
    st.json({
        "model": selected_model,
        "voice": selected_voice,
        "file_size": file_size,
        "processing_time": processing_time,
        "api_response": api_response_dict
    })

# ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ç›£è¦–
performance_metrics = {
    "processing_time": end_time - start_time,
    "file_size_mb": file_size / (1024 * 1024),
    "characters_processed": len(text),
    "estimated_cost": calculate_cost(model, usage)
}
```

---

## ğŸ‰ ã¾ã¨ã‚

ã“ã®è¨­è¨ˆæ›¸ã¯ã€**a10_04_audio_speeches.py** ã®åŒ…æ‹¬çš„ãªæŠ€è¡“ä»•æ§˜ã¨å®Ÿè£…è©³ç´°ã‚’ç¶²ç¾…ã—ãŸå®Œå…¨ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã§ã™ã€‚

### ğŸŒŸ è¨­è¨ˆã®ãƒã‚¤ãƒ©ã‚¤ãƒˆ

- **ğŸµ åŒ…æ‹¬çš„éŸ³å£°å‡¦ç†**: TTSãƒ»STTãƒ»ç¿»è¨³ãƒ»ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ»ãƒã‚§ãƒ¼ãƒ³ã®å…¨æ©Ÿèƒ½çµ±åˆ
- **ğŸ”„ ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¯¾å¿œ**: é«˜åŠ¹ç‡ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ éŸ³å£°å‡¦ç†
- **ğŸ›¡ï¸ å …ç‰¢æ€§**: åŒ…æ‹¬çš„ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã¨ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ©Ÿèƒ½
- **ğŸ’° ã‚³ã‚¹ãƒˆé€æ˜æ€§**: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ã‚³ã‚¹ãƒˆè¨ˆç®—ãƒ»ä½¿ç”¨é‡è¿½è·¡
- **ğŸ¨ ç›´æ„Ÿçš„UI**: Streamlitã«ã‚ˆã‚‹ä½¿ã„ã‚„ã™ã„ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹

### ğŸ”§ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ç‰¹å¾´

- **ğŸ“¦ ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«è¨­è¨ˆ**: BaseDemoç¶™æ‰¿ã«ã‚ˆã‚‹çµ±ä¸€ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
- **ğŸ”„ éåŒæœŸå‡¦ç†**: ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ APIã§ã®é«˜æ€§èƒ½WebSocketé€šä¿¡
- **ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«çµ±åˆç®¡ç†**: éŸ³å£°ãƒ»ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ã®çµ±ä¸€çš„ç®¡ç†ã‚·ã‚¹ãƒ†ãƒ 
- **âš™ï¸ è¨­å®šé§†å‹•**: config.ymlã«ã‚ˆã‚‹æŸ”è»Ÿãªãƒ¢ãƒ‡ãƒ«ãƒ»ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç®¡ç†
- **ğŸ¯ æ®µéšçš„è¤‡é›‘åº¦**: åŸºæœ¬æ©Ÿèƒ½ã‹ã‚‰é«˜åº¦ãªãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‡¦ç†ã¾ã§å¯¾å¿œ